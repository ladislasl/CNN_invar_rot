Rotational-invariant-CNN-
1- Description

Project Title: Rotation invariant polar convolutional layers

Abstract: Many domains involve data that bears inherent rotational invariance. Neural networks architectures that exploit this invariance can benefit from a better representation of data and ultimately generalize better, similarly to the convolutional neural network for translation invariance. Several works have designed rotation invariant layers by building on top of the traditional convolution operator. In this work, we propose a novel type of convolution operator that works in the polar space which is rotationally invariant by construction. Moreover, polar convolution scales linearly with respect to filter size, allowing to significantly reduce the size of the parameter space of neural networks. This highly modular operator can substitute the traditional convolution in any type of architecture. We demonstrate its high potentials on traditional rotation invariant datasets for image classification and segmentation, where this design achieves competitive results at no additional memory cost. Notably, we investigate the optimal way to use polar convolution layers in convolutional architectures. Our code and our experiments are made open-source.

Created on: Wed, 10 Mar 2021 21:34:13 GMT

Last Modified: Wed, 10 Mar 2021 21:34:13 GMT

Authors: Marvin LEROUSSEAU - marvin.lerousseau@gmail.com (Primary) Hugues Talbot - hugues.talbot@centralesupelec.fr

Primary Subject Area: Machine learning architectures and formulations

Secondary Subject Areas: Medical, biological, and cell microscopy Vision applications and systems

2- Quelques articles & presentations

A- https://hal.archives-ouvertes.fr/hal-02022802/document B- https://arxiv.org/pdf/1604.06720.pdf C- https://ieeexplore.ieee.org/abstract/document/8462057 D- https://arxiv.org/pdf/2004.03037.pdf