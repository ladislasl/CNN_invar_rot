{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cercles_concentriques.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN/qiVkeuaCh5lZ9e294Ev2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ladislasl/CNN_invar_rot/blob/main/cercles_concentriquestho.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvvrapehi-Wo"
      },
      "outputs": [],
      "source": [
        "\n",
        "!wget http://www.iro.umontreal.ca/~lisa/icml2007data/mnist_rotation_new.zip\n",
        "!unzip mnist_rotation_new.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tagpr-cpjGem"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.loadtxt('mnist_all_rotation_normalized_float_train_valid.amat')"
      ],
      "metadata": {
        "id": "Vssw5PB7jUeu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data[:10000]\n",
        "val_data = data[10000:]\n",
        "assert len(train_data) + len(val_data) == len(data)\n",
        "train_features, train_labels = train_data[..., :-1], train_data[..., -1]\n",
        "val_features, val_labels = val_data[..., :-1], val_data[..., -1]"
      ],
      "metadata": {
        "id": "bBkyohfSjUoT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = np.reshape(train_features, (-1, 28, 28))\n",
        "val_features = np.reshape(val_features, (-1, 28, 28))"
      ],
      "metadata": {
        "id": "B9-BeuThjdtO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_features[0])\n",
        "plt.title('label: {}'.format(train_labels[0]))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "uY4SHLj3jhio",
        "outputId": "86c7977e-2302-4ebb-e795-04818885485c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "\n",
        "class RotMNISTDataset(Dataset):\n",
        "    def __init__(self, features, labels, transform):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        features = self.transform(self.features[item])\n",
        "\n",
        "        return features.float(), int(self.labels[item])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "rWHFJ0uRnRVr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.utils import _single, _pair, _triple\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, conv_types, kernel_size=3, padding=0):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv_layers = []\n",
        "        # n_inputs_width_fc = 28\n",
        "        for c, conv_type in enumerate(conv_types.split(' ')):\n",
        "            if conv_type == 'C':\n",
        "                conv_op = nn.Conv2d\n",
        "            elif conv_type == 'P':\n",
        "                conv_op = PolarConvNd\n",
        "            else:\n",
        "                raise ValueError(f'Unknown conv type {conv_type}')\n",
        "            conv_args = [1 if c == 0 else 32 * 2**c, 32 * 2**(c+1), kernel_size, 1, padding]\n",
        "            self.conv_layers.append(conv_op(*conv_args))\n",
        "        self.conv_layers = nn.ModuleList(self.conv_layers)\n",
        "        self.conv_types = conv_types\n",
        "\n",
        "        self.adaptive_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.classification_layer = nn.Linear(32 * 2**(c+1), 10, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for conv_layer in self.conv_layers:\n",
        "            x = conv_layer(x)\n",
        "            x = F.relu(x)\n",
        "        x = self.adaptive_pooling(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.classification_layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GroupEquivariantNet(nn.Module):\n",
        "    \"\"\" a CNN architecture (Z2CNN) with 7 layers of 3×3 convolutions (4×4 in the final layer), \n",
        "    20 channels in each layer, relu activation functions, batch normalization, dropout, and max-pooling after layer2 \"\"\"\n",
        "    def __init__(self, conv_types, kernel_size=3, padding=0):\n",
        "        super(GroupEquivariantNet, self).__init__()\n",
        "\n",
        "        self.conv_layers = []\n",
        "        self.bn_layers = []\n",
        "        assert len(conv_types.split(' ')) == 7, 'expects 7 conv layers'\n",
        "        # n_inputs_width_fc = 28\n",
        "        for c, conv_type in enumerate(conv_types.split(' ')):\n",
        "            if conv_type == 'C':\n",
        "                conv_op = nn.Conv2d\n",
        "            elif conv_type == 'P':\n",
        "                conv_op = PolarConvNd\n",
        "            else:\n",
        "                raise ValueError(f'Unknown conv type {conv_type}')\n",
        "            conv_args = [1 if c == 0 else 20, 20, kernel_size, 1, padding]\n",
        "            self.conv_layers.append(conv_op(*conv_args))\n",
        "            self.bn_layers.append(nn.BatchNorm2d(20))\n",
        "            # n_inputs_width_fc -= ((kernel_size // 2) - padding) * 2\n",
        "        self.conv_layers = nn.ModuleList(self.conv_layers)\n",
        "        self.bn_layers = nn.ModuleList(self.bn_layers)\n",
        "        self.conv_types = conv_types\n",
        "\n",
        "        self.max_pooling = nn.MaxPool2d((2, 2))\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "        self.adaptive_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.classification_layer = nn.Linear(80, 10, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for c, (conv_layer, bn_layer) in enumerate(zip(self.conv_layers, self.bn_layers)):\n",
        "            x = conv_layer(x)\n",
        "            x = bn_layer(x)\n",
        "            x = F.relu(x)\n",
        "            x = self.dropout(x)\n",
        "            if c == 1:\n",
        "              x = self.max_pooling(x)\n",
        "        # x = self.adaptive_pooling(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.classification_layer(x)\n",
        "        return x\n",
        "\n",
        "    def __repr__(self):\n",
        "        return 'GroupEquivariantNet(' + str(self.conv_types) + ')'\n",
        "\n",
        "\n",
        "class PolarConvNd(torch.nn.modules.conv._ConvNd):\n",
        "    \"\"\" Polar convolution \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0,\n",
        "                 dilation=1, groups=1, bias=True, padding_mode='zeros', dimensions=2):\n",
        "        self.init_kernel_size = kernel_size\n",
        "        assert kernel_size % 2 == 1, 'expected kernel size to be odd, found %d' % kernel_size\n",
        "        self.init_dimensions = dimensions\n",
        "\n",
        "        base_vectors = torch.from_numpy(self.build_base_vectors()).float()\n",
        "        self.true_base_vectors_shape = base_vectors.shape\n",
        "        base_vectors = base_vectors.view(self.true_base_vectors_shape[0],\n",
        "                                                   int(np.prod(self.true_base_vectors_shape[1:])))\n",
        "\n",
        "        inferred_kernel_size = self.true_base_vectors_shape[0]\n",
        "        _kernel_size = _single(inferred_kernel_size)\n",
        "        _stride = _single(stride)\n",
        "        _padding = _single(padding)\n",
        "        _dilation = _single(dilation)\n",
        "        super(PolarConvNd, self).__init__(\n",
        "            in_channels, out_channels, _kernel_size, _stride, _padding, _dilation,\n",
        "            False, _single(0), groups, bias, padding_mode)\n",
        "        \n",
        "        self.register_buffer('base_vectors', base_vectors)\n",
        "\n",
        "        if dimensions == 2:\n",
        "            self.reconstructed_stride = _pair(stride)\n",
        "            self.reconstructed_padding = _pair(padding)\n",
        "            self.reconstructed_dilation = _pair(dilation)\n",
        "            self.reconstructed_conv_op = F.conv2d\n",
        "        elif dimensions == 3:\n",
        "            self.reconstructed_stride = _triple(stride)\n",
        "            self.reconstructed_padding = _triple(padding)\n",
        "            self.reconstructed_dilation = _triple(dilation)\n",
        "            self.reconstructed_conv_op = F.conv3d\n",
        "        else:\n",
        "            raise ValueError('dimension %d not supported' % dimensions)\n",
        "\n",
        "    def build_base_vectors(self):\n",
        "        kernel_size = self.init_kernel_size\n",
        "        dimensions = self.init_dimensions\n",
        "        base_vectors = []\n",
        "        taille = kernel_size\n",
        "        centre = taille/2 \n",
        "        for k in range (0,taille//2):\n",
        "            base= np.zeros([taille]*dimensions)\n",
        "            for i in range(taille):\n",
        "                for j in range(taille):\n",
        "                \n",
        "                    if np.sqrt(((i+0.5)-centre)**2 + ((j+0.5)-centre)**2)< k+0.1 and np.sqrt(((i+0.5)-centre)**2 + ((j+0.5)-centre)**2) > k-0.6:\n",
        "                        base[i,j]=1\n",
        "                        base[j,i]=1\n",
        "            base_vectors.append(base)\n",
        "        \n",
        "        base_vectors = np.asarray(base_vectors)\n",
        "        return base_vectors\n",
        "\n",
        "    # @weak_script_method\n",
        "    def forward(self, input):\n",
        "        weight_size = self.weight.shape\n",
        "        weight = torch.mm(self.weight.view(np.prod(weight_size[:-1]), weight_size[-1]), self.base_vectors) \\\n",
        "            .view(*weight_size[:-1], *self.true_base_vectors_shape[1:])\n",
        "        return self.reconstructed_conv_op(input, weight, self.bias, self.reconstructed_stride,\n",
        "                                          self.reconstructed_padding, self.reconstructed_dilation, self.groups)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return ('PolarConv%dd' % self.init_dimensions) + '(' + self.extra_repr() + ')'"
      ],
      "metadata": {
        "id": "dSEOLtzknfmX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = 5\n",
        "padding = kernel_size // 2\n",
        "Net('C P C P', kernel_size, padding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB936iyUnhXD",
        "outputId": "9fdb0936-59d7-4117-cc70-d8ed827c78fa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv_layers): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): PolarConv2d(64, 128, kernel_size=(2,), stride=(1,), padding=(2,))\n",
              "    (2): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (3): PolarConv2d(256, 512, kernel_size=(2,), stride=(1,), padding=(2,))\n",
              "  )\n",
              "  (adaptive_pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (classification_layer): Linear(in_features=512, out_features=10, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "\n",
        "def main(models_types, batch_size, learning_rate, n_epochs, kernel_size=3):\n",
        "    cuda_kwargs = {'num_workers': 1, 'pin_memory': True, 'shuffle': True}\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "    \n",
        "    train_dataset = RotMNISTDataset(train_features, train_labels, transform)\n",
        "    val_dataset = RotMNISTDataset(val_features, val_labels, transform)\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, **cuda_kwargs)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, **cuda_kwargs)\n",
        "    \n",
        "    models = []\n",
        "    optimizers = []\n",
        "    for model_type in models_types:\n",
        "        if isinstance(model_type, str):\n",
        "            model = Net(model_type, kernel_size, padding=kernel_size // 2).to(device)\n",
        "        else:\n",
        "            model = model_type.to(device)\n",
        "        models.append(model)\n",
        "        optimizers.append(optim.Adam(model.parameters(), lr=learning_rate))\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    val_losses = [[] for _ in range(len(models))]\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        train(models, device, train_dataloader, loss, optimizers, epoch, models_types)\n",
        "        models_val_loss = val(models, device, val_dataloader, loss, models_types)\n",
        "        [val_losses[i].append(model_val_loss) for i, model_val_loss in enumerate(models_val_loss)]\n",
        "    return val_losses\n",
        "\n",
        "\n",
        "def train(models, device, train_loader, loss_fct, optimizers, epoch, models_types):\n",
        "    [model.train() for model in models]\n",
        "    epoch_losses = [[] for _ in range(len(models))]\n",
        "    corrects = [0 for _ in range(len(models))]\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        for m, (model, optimizer) in enumerate(zip(models, optimizers)):\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = loss_fct(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_losses[m].append(loss.item())\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            corrects[m] += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "              print('{}  Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.4f} ({:.4f}), Accuracy: {:.1f}%'.format(\n",
        "                  models_types[m], epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                  100. * batch_idx / len(train_loader.dataset), loss.item(), np.mean(epoch_losses[m]),\n",
        "                  100. * corrects[m] / (len(epoch_losses[m]) * batch_size)))\n",
        "\n",
        "\n",
        "def val(models, device, val_loader, loss_fct, models_types):\n",
        "    [model.eval() for model in models]\n",
        "    val_losses = [0 for _ in range(len(models))]\n",
        "    corrects = [0 for _ in range(len(models))]\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            for m, model in enumerate(models):\n",
        "                output = model(data)\n",
        "                val_losses[m] += loss_fct(output, target).item()  # sum up batch loss\n",
        "                pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "                corrects[m] += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    val_losses = [val_loss / len(val_loader) for val_loss in val_losses]\n",
        "    for val_loss, model_type, correct, val_loss in zip(val_losses, models_types, corrects, val_losses):\n",
        "        print('\\nval set: {} Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            model_type, val_loss, correct, len(val_loader.dataset),\n",
        "            100. * correct / len(val_loader.dataset)))\n",
        "    return val_losses"
      ],
      "metadata": {
        "id": "dWxhMQJznmMM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computes number of parameters with same filter width\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model, model_name):\n",
        "    table = PrettyTable([model_name, \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "\n",
        "count_parameters(GroupEquivariantNet('C C C C C C C', kernel_size=3, padding=0), 'C C C C C C C')\n",
        "count_parameters(GroupEquivariantNet('C C C C C C P', kernel_size=3, padding=0), 'C C C C C C P')\n",
        "count_parameters(GroupEquivariantNet('C C C C C P P', kernel_size=3, padding=0), 'C C C C C P P')\n",
        "count_parameters(GroupEquivariantNet('C C C C P P P', kernel_size=3, padding=0), 'C C C C P P P')\n",
        "count_parameters(GroupEquivariantNet('C C C P P P P', kernel_size=3, padding=0), 'C C C P P P P')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yg1O5JRnsQl",
        "outputId": "91cb36a5-9ab2-4ba6-c538-8063d9d92056"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+------------+\n",
            "|        C C C C C C C        | Parameters |\n",
            "+-----------------------------+------------+\n",
            "|     conv_layers.0.weight    |    180     |\n",
            "|      conv_layers.0.bias     |     20     |\n",
            "|     conv_layers.1.weight    |    3600    |\n",
            "|      conv_layers.1.bias     |     20     |\n",
            "|     conv_layers.2.weight    |    3600    |\n",
            "|      conv_layers.2.bias     |     20     |\n",
            "|     conv_layers.3.weight    |    3600    |\n",
            "|      conv_layers.3.bias     |     20     |\n",
            "|     conv_layers.4.weight    |    3600    |\n",
            "|      conv_layers.4.bias     |     20     |\n",
            "|     conv_layers.5.weight    |    3600    |\n",
            "|      conv_layers.5.bias     |     20     |\n",
            "|     conv_layers.6.weight    |    3600    |\n",
            "|      conv_layers.6.bias     |     20     |\n",
            "|      bn_layers.0.weight     |     20     |\n",
            "|       bn_layers.0.bias      |     20     |\n",
            "|      bn_layers.1.weight     |     20     |\n",
            "|       bn_layers.1.bias      |     20     |\n",
            "|      bn_layers.2.weight     |     20     |\n",
            "|       bn_layers.2.bias      |     20     |\n",
            "|      bn_layers.3.weight     |     20     |\n",
            "|       bn_layers.3.bias      |     20     |\n",
            "|      bn_layers.4.weight     |     20     |\n",
            "|       bn_layers.4.bias      |     20     |\n",
            "|      bn_layers.5.weight     |     20     |\n",
            "|       bn_layers.5.bias      |     20     |\n",
            "|      bn_layers.6.weight     |     20     |\n",
            "|       bn_layers.6.bias      |     20     |\n",
            "| classification_layer.weight |    800     |\n",
            "+-----------------------------+------------+\n",
            "Total Trainable Params: 23000\n",
            "+-----------------------------+------------+\n",
            "|        C C C C C C P        | Parameters |\n",
            "+-----------------------------+------------+\n",
            "|     conv_layers.0.weight    |    180     |\n",
            "|      conv_layers.0.bias     |     20     |\n",
            "|     conv_layers.1.weight    |    3600    |\n",
            "|      conv_layers.1.bias     |     20     |\n",
            "|     conv_layers.2.weight    |    3600    |\n",
            "|      conv_layers.2.bias     |     20     |\n",
            "|     conv_layers.3.weight    |    3600    |\n",
            "|      conv_layers.3.bias     |     20     |\n",
            "|     conv_layers.4.weight    |    3600    |\n",
            "|      conv_layers.4.bias     |     20     |\n",
            "|     conv_layers.5.weight    |    3600    |\n",
            "|      conv_layers.5.bias     |     20     |\n",
            "|     conv_layers.6.weight    |    400     |\n",
            "|      conv_layers.6.bias     |     20     |\n",
            "|      bn_layers.0.weight     |     20     |\n",
            "|       bn_layers.0.bias      |     20     |\n",
            "|      bn_layers.1.weight     |     20     |\n",
            "|       bn_layers.1.bias      |     20     |\n",
            "|      bn_layers.2.weight     |     20     |\n",
            "|       bn_layers.2.bias      |     20     |\n",
            "|      bn_layers.3.weight     |     20     |\n",
            "|       bn_layers.3.bias      |     20     |\n",
            "|      bn_layers.4.weight     |     20     |\n",
            "|       bn_layers.4.bias      |     20     |\n",
            "|      bn_layers.5.weight     |     20     |\n",
            "|       bn_layers.5.bias      |     20     |\n",
            "|      bn_layers.6.weight     |     20     |\n",
            "|       bn_layers.6.bias      |     20     |\n",
            "| classification_layer.weight |    800     |\n",
            "+-----------------------------+------------+\n",
            "Total Trainable Params: 19800\n",
            "+-----------------------------+------------+\n",
            "|        C C C C C P P        | Parameters |\n",
            "+-----------------------------+------------+\n",
            "|     conv_layers.0.weight    |    180     |\n",
            "|      conv_layers.0.bias     |     20     |\n",
            "|     conv_layers.1.weight    |    3600    |\n",
            "|      conv_layers.1.bias     |     20     |\n",
            "|     conv_layers.2.weight    |    3600    |\n",
            "|      conv_layers.2.bias     |     20     |\n",
            "|     conv_layers.3.weight    |    3600    |\n",
            "|      conv_layers.3.bias     |     20     |\n",
            "|     conv_layers.4.weight    |    3600    |\n",
            "|      conv_layers.4.bias     |     20     |\n",
            "|     conv_layers.5.weight    |    400     |\n",
            "|      conv_layers.5.bias     |     20     |\n",
            "|     conv_layers.6.weight    |    400     |\n",
            "|      conv_layers.6.bias     |     20     |\n",
            "|      bn_layers.0.weight     |     20     |\n",
            "|       bn_layers.0.bias      |     20     |\n",
            "|      bn_layers.1.weight     |     20     |\n",
            "|       bn_layers.1.bias      |     20     |\n",
            "|      bn_layers.2.weight     |     20     |\n",
            "|       bn_layers.2.bias      |     20     |\n",
            "|      bn_layers.3.weight     |     20     |\n",
            "|       bn_layers.3.bias      |     20     |\n",
            "|      bn_layers.4.weight     |     20     |\n",
            "|       bn_layers.4.bias      |     20     |\n",
            "|      bn_layers.5.weight     |     20     |\n",
            "|       bn_layers.5.bias      |     20     |\n",
            "|      bn_layers.6.weight     |     20     |\n",
            "|       bn_layers.6.bias      |     20     |\n",
            "| classification_layer.weight |    800     |\n",
            "+-----------------------------+------------+\n",
            "Total Trainable Params: 16600\n",
            "+-----------------------------+------------+\n",
            "|        C C C C P P P        | Parameters |\n",
            "+-----------------------------+------------+\n",
            "|     conv_layers.0.weight    |    180     |\n",
            "|      conv_layers.0.bias     |     20     |\n",
            "|     conv_layers.1.weight    |    3600    |\n",
            "|      conv_layers.1.bias     |     20     |\n",
            "|     conv_layers.2.weight    |    3600    |\n",
            "|      conv_layers.2.bias     |     20     |\n",
            "|     conv_layers.3.weight    |    3600    |\n",
            "|      conv_layers.3.bias     |     20     |\n",
            "|     conv_layers.4.weight    |    400     |\n",
            "|      conv_layers.4.bias     |     20     |\n",
            "|     conv_layers.5.weight    |    400     |\n",
            "|      conv_layers.5.bias     |     20     |\n",
            "|     conv_layers.6.weight    |    400     |\n",
            "|      conv_layers.6.bias     |     20     |\n",
            "|      bn_layers.0.weight     |     20     |\n",
            "|       bn_layers.0.bias      |     20     |\n",
            "|      bn_layers.1.weight     |     20     |\n",
            "|       bn_layers.1.bias      |     20     |\n",
            "|      bn_layers.2.weight     |     20     |\n",
            "|       bn_layers.2.bias      |     20     |\n",
            "|      bn_layers.3.weight     |     20     |\n",
            "|       bn_layers.3.bias      |     20     |\n",
            "|      bn_layers.4.weight     |     20     |\n",
            "|       bn_layers.4.bias      |     20     |\n",
            "|      bn_layers.5.weight     |     20     |\n",
            "|       bn_layers.5.bias      |     20     |\n",
            "|      bn_layers.6.weight     |     20     |\n",
            "|       bn_layers.6.bias      |     20     |\n",
            "| classification_layer.weight |    800     |\n",
            "+-----------------------------+------------+\n",
            "Total Trainable Params: 13400\n",
            "+-----------------------------+------------+\n",
            "|        C C C P P P P        | Parameters |\n",
            "+-----------------------------+------------+\n",
            "|     conv_layers.0.weight    |    180     |\n",
            "|      conv_layers.0.bias     |     20     |\n",
            "|     conv_layers.1.weight    |    3600    |\n",
            "|      conv_layers.1.bias     |     20     |\n",
            "|     conv_layers.2.weight    |    3600    |\n",
            "|      conv_layers.2.bias     |     20     |\n",
            "|     conv_layers.3.weight    |    400     |\n",
            "|      conv_layers.3.bias     |     20     |\n",
            "|     conv_layers.4.weight    |    400     |\n",
            "|      conv_layers.4.bias     |     20     |\n",
            "|     conv_layers.5.weight    |    400     |\n",
            "|      conv_layers.5.bias     |     20     |\n",
            "|     conv_layers.6.weight    |    400     |\n",
            "|      conv_layers.6.bias     |     20     |\n",
            "|      bn_layers.0.weight     |     20     |\n",
            "|       bn_layers.0.bias      |     20     |\n",
            "|      bn_layers.1.weight     |     20     |\n",
            "|       bn_layers.1.bias      |     20     |\n",
            "|      bn_layers.2.weight     |     20     |\n",
            "|       bn_layers.2.bias      |     20     |\n",
            "|      bn_layers.3.weight     |     20     |\n",
            "|       bn_layers.3.bias      |     20     |\n",
            "|      bn_layers.4.weight     |     20     |\n",
            "|       bn_layers.4.bias      |     20     |\n",
            "|      bn_layers.5.weight     |     20     |\n",
            "|       bn_layers.5.bias      |     20     |\n",
            "|      bn_layers.6.weight     |     20     |\n",
            "|       bn_layers.6.bias      |     20     |\n",
            "| classification_layer.weight |    800     |\n",
            "+-----------------------------+------------+\n",
            "Total Trainable Params: 10200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10200"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "learning_rate = 2e-4\n",
        "n_epochs = 20"
      ],
      "metadata": {
        "id": "-XLSdoMQoPUO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "          GroupEquivariantNet('C C C C C C C', kernel_size=3, padding=0),\n",
        "          GroupEquivariantNet('C C C C C C P', kernel_size=3, padding=0),\n",
        "          GroupEquivariantNet('C C C C C P P', kernel_size=3, padding=0),\n",
        "          GroupEquivariantNet('C C C C P P P', kernel_size=3, padding=0),\n",
        "          GroupEquivariantNet('C C C P P P P', kernel_size=3, padding=0),\n",
        "          ]\n",
        "val_losses = main(models, batch_size, learning_rate, n_epochs, kernel_size=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxHv8lnjoQu-",
        "outputId": "619d7529-1a21-45bf-ccb6-30194d0d8328"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [0/10000 (0%)]\tLoss: 2.4886 (2.4886), Accuracy: 6.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [0/10000 (0%)]\tLoss: 2.4920 (2.4920), Accuracy: 37.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [0/10000 (0%)]\tLoss: 2.4062 (2.4062), Accuracy: 6.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [0/10000 (0%)]\tLoss: 2.4823 (2.4823), Accuracy: 12.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [0/10000 (0%)]\tLoss: 2.4178 (2.4178), Accuracy: 12.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [1600/10000 (1%)]\tLoss: 2.2477 (2.3387), Accuracy: 12.1%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [1600/10000 (1%)]\tLoss: 2.4369 (2.3731), Accuracy: 9.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [1600/10000 (1%)]\tLoss: 2.2505 (2.3531), Accuracy: 11.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [1600/10000 (1%)]\tLoss: 2.3369 (2.3536), Accuracy: 10.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [1600/10000 (1%)]\tLoss: 2.3853 (2.3514), Accuracy: 11.8%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [3200/10000 (2%)]\tLoss: 2.1443 (2.3208), Accuracy: 13.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [3200/10000 (2%)]\tLoss: 2.3087 (2.3434), Accuracy: 10.4%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [3200/10000 (2%)]\tLoss: 2.2774 (2.3350), Accuracy: 12.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [3200/10000 (2%)]\tLoss: 2.3451 (2.3339), Accuracy: 11.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [3200/10000 (2%)]\tLoss: 2.2386 (2.3521), Accuracy: 11.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [4800/10000 (3%)]\tLoss: 2.1183 (2.2884), Accuracy: 15.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [4800/10000 (3%)]\tLoss: 2.1708 (2.3146), Accuracy: 12.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [4800/10000 (3%)]\tLoss: 2.3934 (2.3198), Accuracy: 12.7%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [4800/10000 (3%)]\tLoss: 2.3062 (2.3147), Accuracy: 13.1%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [4800/10000 (3%)]\tLoss: 2.2960 (2.3441), Accuracy: 11.4%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [6400/10000 (4%)]\tLoss: 2.0024 (2.2524), Accuracy: 17.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [6400/10000 (4%)]\tLoss: 2.1971 (2.2864), Accuracy: 14.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [6400/10000 (4%)]\tLoss: 2.1489 (2.2964), Accuracy: 14.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [6400/10000 (4%)]\tLoss: 2.1661 (2.2952), Accuracy: 14.1%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [6400/10000 (4%)]\tLoss: 2.2640 (2.3342), Accuracy: 12.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [8000/10000 (5%)]\tLoss: 2.0596 (2.2221), Accuracy: 19.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [8000/10000 (5%)]\tLoss: 1.8259 (2.2554), Accuracy: 15.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [8000/10000 (5%)]\tLoss: 2.0155 (2.2772), Accuracy: 15.1%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [8000/10000 (5%)]\tLoss: 2.2550 (2.2778), Accuracy: 15.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [8000/10000 (5%)]\tLoss: 2.0494 (2.3238), Accuracy: 12.6%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [9600/10000 (6%)]\tLoss: 1.9368 (2.1869), Accuracy: 21.1%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [9600/10000 (6%)]\tLoss: 2.1489 (2.2271), Accuracy: 17.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [9600/10000 (6%)]\tLoss: 2.2075 (2.2557), Accuracy: 16.3%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [9600/10000 (6%)]\tLoss: 2.1116 (2.2586), Accuracy: 16.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [9600/10000 (6%)]\tLoss: 2.2926 (2.3106), Accuracy: 13.5%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 2.6121, Accuracy: 226/2000 (11%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 1.9848, Accuracy: 523/2000 (26%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 2.1052, Accuracy: 440/2000 (22%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 2.2402, Accuracy: 362/2000 (18%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 2.2922, Accuracy: 206/2000 (10%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [0/10000 (0%)]\tLoss: 1.9238 (1.9238), Accuracy: 25.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [0/10000 (0%)]\tLoss: 1.9517 (1.9517), Accuracy: 37.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [0/10000 (0%)]\tLoss: 2.0726 (2.0726), Accuracy: 31.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [0/10000 (0%)]\tLoss: 2.1931 (2.1931), Accuracy: 18.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [0/10000 (0%)]\tLoss: 2.3567 (2.3567), Accuracy: 12.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [1600/10000 (1%)]\tLoss: 2.0731 (1.9323), Accuracy: 31.7%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [1600/10000 (1%)]\tLoss: 1.9460 (2.0249), Accuracy: 25.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [1600/10000 (1%)]\tLoss: 2.1458 (2.1306), Accuracy: 21.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [1600/10000 (1%)]\tLoss: 2.1129 (2.1118), Accuracy: 24.1%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [1600/10000 (1%)]\tLoss: 2.2170 (2.2260), Accuracy: 18.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [3200/10000 (2%)]\tLoss: 1.5588 (1.8880), Accuracy: 33.6%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [3200/10000 (2%)]\tLoss: 1.8331 (1.9963), Accuracy: 27.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [3200/10000 (2%)]\tLoss: 1.9996 (2.0973), Accuracy: 23.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [3200/10000 (2%)]\tLoss: 1.9603 (2.0874), Accuracy: 25.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [3200/10000 (2%)]\tLoss: 2.1413 (2.2099), Accuracy: 19.6%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [4800/10000 (3%)]\tLoss: 1.7114 (1.8464), Accuracy: 35.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [4800/10000 (3%)]\tLoss: 1.7645 (1.9756), Accuracy: 28.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [4800/10000 (3%)]\tLoss: 2.0100 (2.0782), Accuracy: 24.9%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [4800/10000 (3%)]\tLoss: 1.9690 (2.0651), Accuracy: 26.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [4800/10000 (3%)]\tLoss: 2.0405 (2.1972), Accuracy: 19.9%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [6400/10000 (4%)]\tLoss: 2.0915 (1.8221), Accuracy: 36.1%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [6400/10000 (4%)]\tLoss: 2.1041 (1.9576), Accuracy: 29.1%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [6400/10000 (4%)]\tLoss: 2.3286 (2.0713), Accuracy: 25.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [6400/10000 (4%)]\tLoss: 2.3103 (2.0510), Accuracy: 27.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [6400/10000 (4%)]\tLoss: 2.3338 (2.1906), Accuracy: 19.9%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [8000/10000 (5%)]\tLoss: 1.4715 (1.7929), Accuracy: 37.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [8000/10000 (5%)]\tLoss: 1.5393 (1.9374), Accuracy: 29.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [8000/10000 (5%)]\tLoss: 1.8819 (2.0560), Accuracy: 25.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [8000/10000 (5%)]\tLoss: 1.7886 (2.0299), Accuracy: 27.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [8000/10000 (5%)]\tLoss: 1.9355 (2.1765), Accuracy: 20.4%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [9600/10000 (6%)]\tLoss: 1.5775 (1.7699), Accuracy: 38.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [9600/10000 (6%)]\tLoss: 1.9399 (1.9208), Accuracy: 30.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [9600/10000 (6%)]\tLoss: 1.8497 (2.0435), Accuracy: 25.9%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [9600/10000 (6%)]\tLoss: 1.8606 (2.0080), Accuracy: 28.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [9600/10000 (6%)]\tLoss: 2.1740 (2.1673), Accuracy: 20.3%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 2.5888, Accuracy: 424/2000 (21%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 1.7285, Accuracy: 756/2000 (38%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 1.9284, Accuracy: 506/2000 (25%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 2.1495, Accuracy: 441/2000 (22%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 2.2482, Accuracy: 287/2000 (14%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [0/10000 (0%)]\tLoss: 1.6888 (1.6888), Accuracy: 43.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [0/10000 (0%)]\tLoss: 1.9990 (1.9990), Accuracy: 31.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [0/10000 (0%)]\tLoss: 1.9540 (1.9540), Accuracy: 25.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [0/10000 (0%)]\tLoss: 2.0788 (2.0788), Accuracy: 12.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [0/10000 (0%)]\tLoss: 2.2053 (2.2053), Accuracy: 12.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [1600/10000 (1%)]\tLoss: 1.6969 (1.6065), Accuracy: 44.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [1600/10000 (1%)]\tLoss: 1.7932 (1.8286), Accuracy: 33.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [1600/10000 (1%)]\tLoss: 2.1221 (1.9652), Accuracy: 27.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [1600/10000 (1%)]\tLoss: 2.0700 (1.9211), Accuracy: 30.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [1600/10000 (1%)]\tLoss: 2.2835 (2.1107), Accuracy: 22.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [3200/10000 (2%)]\tLoss: 1.5384 (1.5740), Accuracy: 45.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [3200/10000 (2%)]\tLoss: 1.7091 (1.7921), Accuracy: 35.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [3200/10000 (2%)]\tLoss: 2.1163 (1.9357), Accuracy: 29.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [3200/10000 (2%)]\tLoss: 2.0302 (1.8894), Accuracy: 31.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [3200/10000 (2%)]\tLoss: 2.1454 (2.0920), Accuracy: 22.4%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [4800/10000 (3%)]\tLoss: 1.3198 (1.5449), Accuracy: 46.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [4800/10000 (3%)]\tLoss: 1.5709 (1.7678), Accuracy: 36.1%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [4800/10000 (3%)]\tLoss: 1.7092 (1.9104), Accuracy: 30.4%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [4800/10000 (3%)]\tLoss: 1.7661 (1.8658), Accuracy: 33.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [4800/10000 (3%)]\tLoss: 1.9144 (2.0819), Accuracy: 23.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [6400/10000 (4%)]\tLoss: 1.3458 (1.5317), Accuracy: 47.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [6400/10000 (4%)]\tLoss: 1.7070 (1.7587), Accuracy: 36.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [6400/10000 (4%)]\tLoss: 1.7201 (1.8998), Accuracy: 30.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [6400/10000 (4%)]\tLoss: 1.8557 (1.8571), Accuracy: 32.7%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [6400/10000 (4%)]\tLoss: 2.1043 (2.0771), Accuracy: 22.7%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [8000/10000 (5%)]\tLoss: 1.6943 (1.5177), Accuracy: 48.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [8000/10000 (5%)]\tLoss: 1.7478 (1.7484), Accuracy: 36.9%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [8000/10000 (5%)]\tLoss: 2.0539 (1.8902), Accuracy: 31.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [8000/10000 (5%)]\tLoss: 2.0647 (1.8498), Accuracy: 32.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [8000/10000 (5%)]\tLoss: 2.3283 (2.0728), Accuracy: 22.8%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [9600/10000 (6%)]\tLoss: 1.4374 (1.4968), Accuracy: 48.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [9600/10000 (6%)]\tLoss: 1.6206 (1.7306), Accuracy: 37.6%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [9600/10000 (6%)]\tLoss: 1.8240 (1.8784), Accuracy: 31.3%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [9600/10000 (6%)]\tLoss: 1.8709 (1.8406), Accuracy: 33.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [9600/10000 (6%)]\tLoss: 2.0545 (2.0682), Accuracy: 23.1%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 2.0272, Accuracy: 607/2000 (30%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 1.5769, Accuracy: 893/2000 (45%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 1.7822, Accuracy: 624/2000 (31%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.9960, Accuracy: 489/2000 (24%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 2.1537, Accuracy: 363/2000 (18%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [0/10000 (0%)]\tLoss: 1.0649 (1.0649), Accuracy: 81.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [0/10000 (0%)]\tLoss: 1.4798 (1.4798), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [0/10000 (0%)]\tLoss: 1.6557 (1.6557), Accuracy: 37.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [0/10000 (0%)]\tLoss: 1.6490 (1.6490), Accuracy: 31.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [0/10000 (0%)]\tLoss: 1.7344 (1.7344), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [1600/10000 (1%)]\tLoss: 1.2676 (1.3418), Accuracy: 55.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [1600/10000 (1%)]\tLoss: 1.6293 (1.5985), Accuracy: 44.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [1600/10000 (1%)]\tLoss: 1.6904 (1.7812), Accuracy: 35.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [1600/10000 (1%)]\tLoss: 1.5763 (1.7691), Accuracy: 34.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [1600/10000 (1%)]\tLoss: 2.0213 (2.0086), Accuracy: 25.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [3200/10000 (2%)]\tLoss: 1.2914 (1.3284), Accuracy: 55.4%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [3200/10000 (2%)]\tLoss: 1.1939 (1.5948), Accuracy: 44.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [3200/10000 (2%)]\tLoss: 1.5794 (1.7628), Accuracy: 36.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [3200/10000 (2%)]\tLoss: 1.4643 (1.7617), Accuracy: 34.7%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [3200/10000 (2%)]\tLoss: 1.8473 (2.0095), Accuracy: 25.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [4800/10000 (3%)]\tLoss: 1.1092 (1.3236), Accuracy: 55.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [4800/10000 (3%)]\tLoss: 1.4408 (1.5842), Accuracy: 44.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [4800/10000 (3%)]\tLoss: 1.6532 (1.7562), Accuracy: 36.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [4800/10000 (3%)]\tLoss: 1.5194 (1.7556), Accuracy: 35.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [4800/10000 (3%)]\tLoss: 1.7998 (1.9997), Accuracy: 25.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [6400/10000 (4%)]\tLoss: 1.1244 (1.3056), Accuracy: 56.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [6400/10000 (4%)]\tLoss: 1.4627 (1.5770), Accuracy: 44.9%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [6400/10000 (4%)]\tLoss: 1.7984 (1.7535), Accuracy: 36.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [6400/10000 (4%)]\tLoss: 1.6658 (1.7537), Accuracy: 35.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [6400/10000 (4%)]\tLoss: 2.1189 (1.9979), Accuracy: 25.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [8000/10000 (5%)]\tLoss: 1.1328 (1.3014), Accuracy: 56.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [8000/10000 (5%)]\tLoss: 1.2125 (1.5775), Accuracy: 44.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [8000/10000 (5%)]\tLoss: 1.6166 (1.7591), Accuracy: 36.4%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [8000/10000 (5%)]\tLoss: 1.6161 (1.7559), Accuracy: 35.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [8000/10000 (5%)]\tLoss: 1.8287 (1.9985), Accuracy: 25.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [9600/10000 (6%)]\tLoss: 1.1598 (1.2840), Accuracy: 57.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [9600/10000 (6%)]\tLoss: 1.5484 (1.5616), Accuracy: 45.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [9600/10000 (6%)]\tLoss: 1.7952 (1.7493), Accuracy: 37.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [9600/10000 (6%)]\tLoss: 1.6997 (1.7504), Accuracy: 35.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [9600/10000 (6%)]\tLoss: 2.1854 (1.9947), Accuracy: 25.4%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 1.5489, Accuracy: 882/2000 (44%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 1.3340, Accuracy: 1119/2000 (56%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 1.6573, Accuracy: 797/2000 (40%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.8653, Accuracy: 575/2000 (29%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 2.0193, Accuracy: 491/2000 (25%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 5 [0/10000 (0%)]\tLoss: 1.3034 (1.3034), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 5 [0/10000 (0%)]\tLoss: 1.6292 (1.6292), Accuracy: 31.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 5 [0/10000 (0%)]\tLoss: 1.7336 (1.7336), Accuracy: 31.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 5 [0/10000 (0%)]\tLoss: 1.6104 (1.6104), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 5 [0/10000 (0%)]\tLoss: 1.6653 (1.6653), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 5 [1600/10000 (1%)]\tLoss: 0.9581 (1.1497), Accuracy: 63.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 5 [1600/10000 (1%)]\tLoss: 1.0576 (1.4477), Accuracy: 48.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 5 [1600/10000 (1%)]\tLoss: 1.5782 (1.6635), Accuracy: 38.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 5 [1600/10000 (1%)]\tLoss: 1.7024 (1.6914), Accuracy: 38.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 5 [1600/10000 (1%)]\tLoss: 1.8312 (1.9279), Accuracy: 29.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 5 [3200/10000 (2%)]\tLoss: 1.0876 (1.1222), Accuracy: 64.1%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 5 [3200/10000 (2%)]\tLoss: 1.4866 (1.4318), Accuracy: 49.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 5 [3200/10000 (2%)]\tLoss: 1.6629 (1.6758), Accuracy: 39.3%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 5 [3200/10000 (2%)]\tLoss: 1.6304 (1.6953), Accuracy: 37.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 5 [3200/10000 (2%)]\tLoss: 1.8688 (1.9328), Accuracy: 28.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 5 [4800/10000 (3%)]\tLoss: 1.2690 (1.1207), Accuracy: 64.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 5 [4800/10000 (3%)]\tLoss: 1.7400 (1.4379), Accuracy: 49.6%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 5 [4800/10000 (3%)]\tLoss: 1.9081 (1.6794), Accuracy: 39.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 5 [4800/10000 (3%)]\tLoss: 2.0109 (1.6960), Accuracy: 36.9%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 5 [4800/10000 (3%)]\tLoss: 2.2908 (1.9417), Accuracy: 28.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 5 [6400/10000 (4%)]\tLoss: 0.7049 (1.1033), Accuracy: 64.6%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 5 [6400/10000 (4%)]\tLoss: 1.2460 (1.4177), Accuracy: 50.4%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 5 [6400/10000 (4%)]\tLoss: 1.2701 (1.6700), Accuracy: 39.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 5 [6400/10000 (4%)]\tLoss: 1.3323 (1.6872), Accuracy: 37.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 5 [6400/10000 (4%)]\tLoss: 1.7391 (1.9287), Accuracy: 28.6%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 5 [8000/10000 (5%)]\tLoss: 1.2940 (1.0918), Accuracy: 64.7%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 5 [8000/10000 (5%)]\tLoss: 1.2847 (1.4029), Accuracy: 51.1%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 5 [8000/10000 (5%)]\tLoss: 1.3313 (1.6615), Accuracy: 40.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 5 [8000/10000 (5%)]\tLoss: 1.7017 (1.6883), Accuracy: 37.9%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 5 [8000/10000 (5%)]\tLoss: 1.8752 (1.9225), Accuracy: 28.6%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 5 [9600/10000 (6%)]\tLoss: 0.7703 (1.0716), Accuracy: 65.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 5 [9600/10000 (6%)]\tLoss: 1.2003 (1.3879), Accuracy: 51.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 5 [9600/10000 (6%)]\tLoss: 1.6479 (1.6508), Accuracy: 40.3%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 5 [9600/10000 (6%)]\tLoss: 1.6783 (1.6810), Accuracy: 38.1%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 5 [9600/10000 (6%)]\tLoss: 2.0719 (1.9175), Accuracy: 28.8%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 1.3932, Accuracy: 1007/2000 (50%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 1.1328, Accuracy: 1272/2000 (64%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 1.5685, Accuracy: 887/2000 (44%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.9482, Accuracy: 569/2000 (28%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.9099, Accuracy: 592/2000 (30%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 6 [0/10000 (0%)]\tLoss: 1.3016 (1.3016), Accuracy: 37.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 6 [0/10000 (0%)]\tLoss: 1.2252 (1.2252), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 6 [0/10000 (0%)]\tLoss: 1.5750 (1.5750), Accuracy: 31.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 6 [0/10000 (0%)]\tLoss: 1.5436 (1.5436), Accuracy: 43.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 6 [0/10000 (0%)]\tLoss: 1.8803 (1.8803), Accuracy: 31.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 6 [1600/10000 (1%)]\tLoss: 0.9863 (0.9870), Accuracy: 67.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 6 [1600/10000 (1%)]\tLoss: 1.1488 (1.3067), Accuracy: 55.1%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 6 [1600/10000 (1%)]\tLoss: 1.4412 (1.6219), Accuracy: 40.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 6 [1600/10000 (1%)]\tLoss: 1.4518 (1.6553), Accuracy: 40.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 6 [1600/10000 (1%)]\tLoss: 1.6726 (1.8784), Accuracy: 29.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 6 [3200/10000 (2%)]\tLoss: 1.0408 (0.9910), Accuracy: 67.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 6 [3200/10000 (2%)]\tLoss: 1.0688 (1.2867), Accuracy: 56.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 6 [3200/10000 (2%)]\tLoss: 1.4273 (1.5939), Accuracy: 41.9%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 6 [3200/10000 (2%)]\tLoss: 1.4776 (1.6324), Accuracy: 40.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 6 [3200/10000 (2%)]\tLoss: 1.7056 (1.8577), Accuracy: 30.4%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 6 [4800/10000 (3%)]\tLoss: 1.0919 (0.9661), Accuracy: 69.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 6 [4800/10000 (3%)]\tLoss: 1.0802 (1.2610), Accuracy: 57.1%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 6 [4800/10000 (3%)]\tLoss: 1.5412 (1.5742), Accuracy: 42.7%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 6 [4800/10000 (3%)]\tLoss: 1.6297 (1.6271), Accuracy: 40.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 6 [4800/10000 (3%)]\tLoss: 1.8384 (1.8541), Accuracy: 30.7%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 6 [6400/10000 (4%)]\tLoss: 0.6506 (0.9528), Accuracy: 69.6%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 6 [6400/10000 (4%)]\tLoss: 0.9035 (1.2475), Accuracy: 57.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 6 [6400/10000 (4%)]\tLoss: 1.3686 (1.5633), Accuracy: 43.3%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 6 [6400/10000 (4%)]\tLoss: 1.4369 (1.6284), Accuracy: 39.9%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 6 [6400/10000 (4%)]\tLoss: 1.8756 (1.8546), Accuracy: 30.8%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 6 [8000/10000 (5%)]\tLoss: 0.8206 (0.9486), Accuracy: 69.6%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 6 [8000/10000 (5%)]\tLoss: 1.3320 (1.2352), Accuracy: 57.9%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 6 [8000/10000 (5%)]\tLoss: 1.6557 (1.5572), Accuracy: 43.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 6 [8000/10000 (5%)]\tLoss: 1.5413 (1.6288), Accuracy: 39.9%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 6 [8000/10000 (5%)]\tLoss: 1.6144 (1.8480), Accuracy: 31.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 6 [9600/10000 (6%)]\tLoss: 0.7053 (0.9371), Accuracy: 69.9%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 6 [9600/10000 (6%)]\tLoss: 1.3159 (1.2237), Accuracy: 58.4%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 6 [9600/10000 (6%)]\tLoss: 1.3402 (1.5470), Accuracy: 44.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 6 [9600/10000 (6%)]\tLoss: 1.4138 (1.6289), Accuracy: 40.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 6 [9600/10000 (6%)]\tLoss: 1.6256 (1.8464), Accuracy: 31.1%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 0.9687, Accuracy: 1327/2000 (66%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 0.9656, Accuracy: 1396/2000 (70%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 1.3810, Accuracy: 1090/2000 (54%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.7783, Accuracy: 675/2000 (34%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.8121, Accuracy: 635/2000 (32%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 7 [0/10000 (0%)]\tLoss: 1.0314 (1.0314), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 7 [0/10000 (0%)]\tLoss: 1.2595 (1.2595), Accuracy: 43.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 7 [0/10000 (0%)]\tLoss: 1.3759 (1.3759), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 7 [0/10000 (0%)]\tLoss: 1.5999 (1.5999), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 7 [0/10000 (0%)]\tLoss: 1.7543 (1.7543), Accuracy: 31.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 7 [1600/10000 (1%)]\tLoss: 1.0405 (0.8848), Accuracy: 72.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 7 [1600/10000 (1%)]\tLoss: 1.1975 (1.1281), Accuracy: 61.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 7 [1600/10000 (1%)]\tLoss: 1.7246 (1.4475), Accuracy: 49.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 7 [1600/10000 (1%)]\tLoss: 1.8872 (1.5922), Accuracy: 42.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 7 [1600/10000 (1%)]\tLoss: 2.0114 (1.8024), Accuracy: 33.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 7 [3200/10000 (2%)]\tLoss: 0.8649 (0.8574), Accuracy: 73.1%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 7 [3200/10000 (2%)]\tLoss: 0.9230 (1.1311), Accuracy: 61.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 7 [3200/10000 (2%)]\tLoss: 1.6072 (1.4435), Accuracy: 49.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 7 [3200/10000 (2%)]\tLoss: 1.6833 (1.6033), Accuracy: 41.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 7 [3200/10000 (2%)]\tLoss: 2.0021 (1.8046), Accuracy: 32.8%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 7 [4800/10000 (3%)]\tLoss: 0.4540 (0.8467), Accuracy: 73.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 7 [4800/10000 (3%)]\tLoss: 0.8233 (1.1162), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 7 [4800/10000 (3%)]\tLoss: 1.2122 (1.4387), Accuracy: 49.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 7 [4800/10000 (3%)]\tLoss: 1.3878 (1.5983), Accuracy: 42.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 7 [4800/10000 (3%)]\tLoss: 1.6232 (1.8115), Accuracy: 32.4%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 7 [6400/10000 (4%)]\tLoss: 1.1241 (0.8414), Accuracy: 73.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 7 [6400/10000 (4%)]\tLoss: 1.3988 (1.1142), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 7 [6400/10000 (4%)]\tLoss: 1.8146 (1.4356), Accuracy: 49.3%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 7 [6400/10000 (4%)]\tLoss: 1.8740 (1.6015), Accuracy: 42.1%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 7 [6400/10000 (4%)]\tLoss: 1.7758 (1.8124), Accuracy: 32.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 7 [8000/10000 (5%)]\tLoss: 1.0096 (0.8378), Accuracy: 73.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 7 [8000/10000 (5%)]\tLoss: 1.2224 (1.1070), Accuracy: 63.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 7 [8000/10000 (5%)]\tLoss: 1.6436 (1.4306), Accuracy: 49.7%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 7 [8000/10000 (5%)]\tLoss: 1.6569 (1.5972), Accuracy: 42.4%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 7 [8000/10000 (5%)]\tLoss: 1.7951 (1.8078), Accuracy: 32.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 7 [9600/10000 (6%)]\tLoss: 0.9925 (0.8306), Accuracy: 73.4%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 7 [9600/10000 (6%)]\tLoss: 0.9901 (1.0958), Accuracy: 63.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 7 [9600/10000 (6%)]\tLoss: 1.4159 (1.4244), Accuracy: 49.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 7 [9600/10000 (6%)]\tLoss: 1.5016 (1.5904), Accuracy: 42.4%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 7 [9600/10000 (6%)]\tLoss: 1.9141 (1.8053), Accuracy: 32.2%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 0.8483, Accuracy: 1446/2000 (72%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 0.8359, Accuracy: 1484/2000 (74%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 1.1879, Accuracy: 1230/2000 (62%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.6151, Accuracy: 805/2000 (40%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.7710, Accuracy: 668/2000 (33%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 8 [0/10000 (0%)]\tLoss: 1.4604 (1.4604), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 8 [0/10000 (0%)]\tLoss: 1.2399 (1.2399), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 8 [0/10000 (0%)]\tLoss: 1.6738 (1.6738), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 8 [0/10000 (0%)]\tLoss: 1.9143 (1.9143), Accuracy: 37.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 8 [0/10000 (0%)]\tLoss: 1.7980 (1.7980), Accuracy: 43.8%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 8 [1600/10000 (1%)]\tLoss: 0.9196 (0.7843), Accuracy: 74.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 8 [1600/10000 (1%)]\tLoss: 0.9537 (1.0454), Accuracy: 62.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 8 [1600/10000 (1%)]\tLoss: 1.9125 (1.3805), Accuracy: 53.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 8 [1600/10000 (1%)]\tLoss: 1.5200 (1.5641), Accuracy: 42.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 8 [1600/10000 (1%)]\tLoss: 1.6378 (1.7947), Accuracy: 31.9%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 8 [3200/10000 (2%)]\tLoss: 0.7746 (0.7904), Accuracy: 74.9%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 8 [3200/10000 (2%)]\tLoss: 1.0146 (1.0247), Accuracy: 64.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 8 [3200/10000 (2%)]\tLoss: 1.7099 (1.3708), Accuracy: 52.1%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 8 [3200/10000 (2%)]\tLoss: 1.6892 (1.5677), Accuracy: 41.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 8 [3200/10000 (2%)]\tLoss: 1.7406 (1.7865), Accuracy: 32.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 8 [4800/10000 (3%)]\tLoss: 0.3639 (0.7692), Accuracy: 75.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 8 [4800/10000 (3%)]\tLoss: 0.8109 (1.0185), Accuracy: 64.6%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 8 [4800/10000 (3%)]\tLoss: 0.9235 (1.3522), Accuracy: 52.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 8 [4800/10000 (3%)]\tLoss: 1.2230 (1.5597), Accuracy: 42.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 8 [4800/10000 (3%)]\tLoss: 1.6073 (1.7861), Accuracy: 32.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 8 [6400/10000 (4%)]\tLoss: 0.5492 (0.7527), Accuracy: 75.7%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 8 [6400/10000 (4%)]\tLoss: 0.9306 (1.0077), Accuracy: 65.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 8 [6400/10000 (4%)]\tLoss: 1.1196 (1.3380), Accuracy: 53.1%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 8 [6400/10000 (4%)]\tLoss: 1.2810 (1.5562), Accuracy: 42.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 8 [6400/10000 (4%)]\tLoss: 1.4335 (1.7770), Accuracy: 32.9%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 8 [8000/10000 (5%)]\tLoss: 0.8630 (0.7503), Accuracy: 75.9%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 8 [8000/10000 (5%)]\tLoss: 0.9839 (1.0040), Accuracy: 65.6%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 8 [8000/10000 (5%)]\tLoss: 1.5478 (1.3337), Accuracy: 53.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 8 [8000/10000 (5%)]\tLoss: 1.6825 (1.5558), Accuracy: 42.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 8 [8000/10000 (5%)]\tLoss: 1.9123 (1.7707), Accuracy: 33.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 8 [9600/10000 (6%)]\tLoss: 0.5479 (0.7390), Accuracy: 76.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 8 [9600/10000 (6%)]\tLoss: 0.7250 (0.9934), Accuracy: 66.4%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 8 [9600/10000 (6%)]\tLoss: 1.3830 (1.3212), Accuracy: 53.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 8 [9600/10000 (6%)]\tLoss: 1.4005 (1.5537), Accuracy: 42.9%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 8 [9600/10000 (6%)]\tLoss: 1.5582 (1.7662), Accuracy: 33.3%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 0.6852, Accuracy: 1562/2000 (78%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 0.7333, Accuracy: 1551/2000 (78%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 1.0484, Accuracy: 1338/2000 (67%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.5640, Accuracy: 856/2000 (43%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.7255, Accuracy: 700/2000 (35%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 9 [0/10000 (0%)]\tLoss: 0.4850 (0.4850), Accuracy: 93.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 9 [0/10000 (0%)]\tLoss: 0.5700 (0.5700), Accuracy: 87.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 9 [0/10000 (0%)]\tLoss: 1.0081 (1.0081), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 9 [0/10000 (0%)]\tLoss: 1.1933 (1.1933), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 9 [0/10000 (0%)]\tLoss: 1.3555 (1.3555), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 9 [1600/10000 (1%)]\tLoss: 0.7554 (0.6932), Accuracy: 77.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 9 [1600/10000 (1%)]\tLoss: 1.2079 (0.9092), Accuracy: 69.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 9 [1600/10000 (1%)]\tLoss: 1.4517 (1.2488), Accuracy: 55.3%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 9 [1600/10000 (1%)]\tLoss: 1.6372 (1.4797), Accuracy: 47.1%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 9 [1600/10000 (1%)]\tLoss: 1.8348 (1.7152), Accuracy: 36.6%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 9 [3200/10000 (2%)]\tLoss: 0.4413 (0.7071), Accuracy: 76.9%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 9 [3200/10000 (2%)]\tLoss: 0.5152 (0.9192), Accuracy: 69.1%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 9 [3200/10000 (2%)]\tLoss: 1.0997 (1.2439), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 9 [3200/10000 (2%)]\tLoss: 1.4704 (1.5116), Accuracy: 45.4%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 9 [3200/10000 (2%)]\tLoss: 1.5215 (1.7397), Accuracy: 35.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 9 [4800/10000 (3%)]\tLoss: 0.7711 (0.7001), Accuracy: 77.6%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 9 [4800/10000 (3%)]\tLoss: 1.2437 (0.9269), Accuracy: 68.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 9 [4800/10000 (3%)]\tLoss: 1.2892 (1.2352), Accuracy: 56.7%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 9 [4800/10000 (3%)]\tLoss: 2.2985 (1.5147), Accuracy: 45.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 9 [4800/10000 (3%)]\tLoss: 1.8034 (1.7457), Accuracy: 34.6%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 9 [6400/10000 (4%)]\tLoss: 0.8004 (0.7024), Accuracy: 77.6%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 9 [6400/10000 (4%)]\tLoss: 0.7865 (0.9229), Accuracy: 69.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 9 [6400/10000 (4%)]\tLoss: 1.4067 (1.2267), Accuracy: 57.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 9 [6400/10000 (4%)]\tLoss: 1.9601 (1.5224), Accuracy: 45.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 9 [6400/10000 (4%)]\tLoss: 2.1436 (1.7485), Accuracy: 34.4%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 9 [8000/10000 (5%)]\tLoss: 0.6138 (0.6954), Accuracy: 77.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 9 [8000/10000 (5%)]\tLoss: 0.8835 (0.9101), Accuracy: 69.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 9 [8000/10000 (5%)]\tLoss: 1.2638 (1.2170), Accuracy: 57.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 9 [8000/10000 (5%)]\tLoss: 1.6033 (1.5173), Accuracy: 45.4%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 9 [8000/10000 (5%)]\tLoss: 1.5712 (1.7370), Accuracy: 34.7%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 9 [9600/10000 (6%)]\tLoss: 0.6115 (0.6859), Accuracy: 78.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 9 [9600/10000 (6%)]\tLoss: 0.9498 (0.9046), Accuracy: 69.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 9 [9600/10000 (6%)]\tLoss: 0.9454 (1.2077), Accuracy: 57.7%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 9 [9600/10000 (6%)]\tLoss: 1.5614 (1.5072), Accuracy: 45.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 9 [9600/10000 (6%)]\tLoss: 1.6821 (1.7292), Accuracy: 34.9%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 0.6938, Accuracy: 1548/2000 (77%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 0.6433, Accuracy: 1615/2000 (81%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 0.9529, Accuracy: 1391/2000 (70%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.5271, Accuracy: 893/2000 (45%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.6910, Accuracy: 718/2000 (36%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 10 [0/10000 (0%)]\tLoss: 0.2732 (0.2732), Accuracy: 100.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 10 [0/10000 (0%)]\tLoss: 0.5342 (0.5342), Accuracy: 81.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 10 [0/10000 (0%)]\tLoss: 0.8421 (0.8421), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 10 [0/10000 (0%)]\tLoss: 1.2896 (1.2896), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 10 [0/10000 (0%)]\tLoss: 1.5699 (1.5699), Accuracy: 37.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 10 [1600/10000 (1%)]\tLoss: 0.5422 (0.6662), Accuracy: 79.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 10 [1600/10000 (1%)]\tLoss: 0.6699 (0.8583), Accuracy: 71.9%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 10 [1600/10000 (1%)]\tLoss: 0.9727 (1.1465), Accuracy: 60.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 10 [1600/10000 (1%)]\tLoss: 1.5246 (1.4466), Accuracy: 48.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 10 [1600/10000 (1%)]\tLoss: 1.4916 (1.7155), Accuracy: 35.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 10 [3200/10000 (2%)]\tLoss: 0.4142 (0.6688), Accuracy: 79.6%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 10 [3200/10000 (2%)]\tLoss: 0.6322 (0.8686), Accuracy: 71.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 10 [3200/10000 (2%)]\tLoss: 1.0729 (1.1584), Accuracy: 60.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 10 [3200/10000 (2%)]\tLoss: 1.5486 (1.4699), Accuracy: 47.1%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 10 [3200/10000 (2%)]\tLoss: 1.9736 (1.7303), Accuracy: 35.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 10 [4800/10000 (3%)]\tLoss: 0.8757 (0.6685), Accuracy: 79.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 10 [4800/10000 (3%)]\tLoss: 0.9297 (0.8538), Accuracy: 72.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 10 [4800/10000 (3%)]\tLoss: 1.0715 (1.1416), Accuracy: 60.9%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 10 [4800/10000 (3%)]\tLoss: 1.3676 (1.4852), Accuracy: 46.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 10 [4800/10000 (3%)]\tLoss: 1.3991 (1.7215), Accuracy: 35.4%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 10 [6400/10000 (4%)]\tLoss: 0.7490 (0.6658), Accuracy: 79.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 10 [6400/10000 (4%)]\tLoss: 1.1058 (0.8506), Accuracy: 72.4%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 10 [6400/10000 (4%)]\tLoss: 1.2047 (1.1426), Accuracy: 60.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 10 [6400/10000 (4%)]\tLoss: 1.6917 (1.4809), Accuracy: 47.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 10 [6400/10000 (4%)]\tLoss: 1.9529 (1.7218), Accuracy: 35.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 10 [8000/10000 (5%)]\tLoss: 0.7925 (0.6648), Accuracy: 79.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 10 [8000/10000 (5%)]\tLoss: 0.7429 (0.8465), Accuracy: 72.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 10 [8000/10000 (5%)]\tLoss: 0.8219 (1.1444), Accuracy: 60.7%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 10 [8000/10000 (5%)]\tLoss: 1.3188 (1.4814), Accuracy: 47.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 10 [8000/10000 (5%)]\tLoss: 1.5390 (1.7186), Accuracy: 35.4%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 10 [9600/10000 (6%)]\tLoss: 0.6445 (0.6622), Accuracy: 79.4%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 10 [9600/10000 (6%)]\tLoss: 1.0329 (0.8460), Accuracy: 72.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 10 [9600/10000 (6%)]\tLoss: 1.4272 (1.1404), Accuracy: 60.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 10 [9600/10000 (6%)]\tLoss: 1.4596 (1.4718), Accuracy: 47.4%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 10 [9600/10000 (6%)]\tLoss: 1.8314 (1.7154), Accuracy: 35.5%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 0.5479, Accuracy: 1671/2000 (84%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 0.5856, Accuracy: 1626/2000 (81%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 0.8630, Accuracy: 1444/2000 (72%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.4696, Accuracy: 941/2000 (47%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.6590, Accuracy: 747/2000 (37%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 11 [0/10000 (0%)]\tLoss: 0.5926 (0.5926), Accuracy: 87.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 11 [0/10000 (0%)]\tLoss: 0.8337 (0.8337), Accuracy: 75.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 11 [0/10000 (0%)]\tLoss: 1.1341 (1.1341), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 11 [0/10000 (0%)]\tLoss: 1.4060 (1.4060), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 11 [0/10000 (0%)]\tLoss: 1.7810 (1.7810), Accuracy: 37.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 11 [1600/10000 (1%)]\tLoss: 0.4910 (0.6079), Accuracy: 82.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 11 [1600/10000 (1%)]\tLoss: 0.7153 (0.7669), Accuracy: 74.1%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 11 [1600/10000 (1%)]\tLoss: 0.9321 (1.0811), Accuracy: 61.9%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 11 [1600/10000 (1%)]\tLoss: 1.1316 (1.4524), Accuracy: 47.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 11 [1600/10000 (1%)]\tLoss: 1.6072 (1.6944), Accuracy: 36.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 11 [3200/10000 (2%)]\tLoss: 0.6476 (0.6448), Accuracy: 79.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 11 [3200/10000 (2%)]\tLoss: 0.8092 (0.8012), Accuracy: 73.1%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 11 [3200/10000 (2%)]\tLoss: 1.0797 (1.1013), Accuracy: 61.9%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 11 [3200/10000 (2%)]\tLoss: 1.2291 (1.4665), Accuracy: 47.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 11 [3200/10000 (2%)]\tLoss: 1.6092 (1.7061), Accuracy: 36.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 11 [4800/10000 (3%)]\tLoss: 0.6166 (0.6324), Accuracy: 79.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 11 [4800/10000 (3%)]\tLoss: 0.6391 (0.7908), Accuracy: 73.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 11 [4800/10000 (3%)]\tLoss: 1.0902 (1.0888), Accuracy: 62.4%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 11 [4800/10000 (3%)]\tLoss: 1.4045 (1.4564), Accuracy: 47.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 11 [4800/10000 (3%)]\tLoss: 1.5938 (1.6977), Accuracy: 36.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 11 [6400/10000 (4%)]\tLoss: 0.4552 (0.6193), Accuracy: 80.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 11 [6400/10000 (4%)]\tLoss: 0.6025 (0.7776), Accuracy: 74.6%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 11 [6400/10000 (4%)]\tLoss: 0.8304 (1.0729), Accuracy: 63.4%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 11 [6400/10000 (4%)]\tLoss: 1.0837 (1.4484), Accuracy: 47.9%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 11 [6400/10000 (4%)]\tLoss: 1.5059 (1.6933), Accuracy: 36.6%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 11 [8000/10000 (5%)]\tLoss: 0.4757 (0.6203), Accuracy: 80.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 11 [8000/10000 (5%)]\tLoss: 0.5223 (0.7781), Accuracy: 74.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 11 [8000/10000 (5%)]\tLoss: 0.8650 (1.0742), Accuracy: 63.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 11 [8000/10000 (5%)]\tLoss: 1.2870 (1.4369), Accuracy: 48.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 11 [8000/10000 (5%)]\tLoss: 1.3414 (1.6923), Accuracy: 36.7%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 11 [9600/10000 (6%)]\tLoss: 0.4856 (0.6156), Accuracy: 80.7%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 11 [9600/10000 (6%)]\tLoss: 0.5762 (0.7764), Accuracy: 74.9%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 11 [9600/10000 (6%)]\tLoss: 0.8331 (1.0750), Accuracy: 63.3%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 11 [9600/10000 (6%)]\tLoss: 1.2851 (1.4295), Accuracy: 48.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 11 [9600/10000 (6%)]\tLoss: 1.9164 (1.6919), Accuracy: 36.8%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 0.5289, Accuracy: 1681/2000 (84%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 0.5438, Accuracy: 1671/2000 (84%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 0.7811, Accuracy: 1516/2000 (76%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.4002, Accuracy: 986/2000 (49%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.6114, Accuracy: 793/2000 (40%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 12 [0/10000 (0%)]\tLoss: 0.4109 (0.4109), Accuracy: 87.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 12 [0/10000 (0%)]\tLoss: 0.8196 (0.8196), Accuracy: 68.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 12 [0/10000 (0%)]\tLoss: 0.9559 (0.9559), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 12 [0/10000 (0%)]\tLoss: 1.1773 (1.1773), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 12 [0/10000 (0%)]\tLoss: 1.3852 (1.3852), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 12 [1600/10000 (1%)]\tLoss: 0.2960 (0.6039), Accuracy: 80.7%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 12 [1600/10000 (1%)]\tLoss: 0.5813 (0.7877), Accuracy: 74.9%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 12 [1600/10000 (1%)]\tLoss: 0.8089 (1.0327), Accuracy: 64.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 12 [1600/10000 (1%)]\tLoss: 1.1653 (1.3958), Accuracy: 49.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 12 [1600/10000 (1%)]\tLoss: 1.6832 (1.6633), Accuracy: 37.4%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 12 [3200/10000 (2%)]\tLoss: 0.3556 (0.5938), Accuracy: 81.4%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 12 [3200/10000 (2%)]\tLoss: 0.3297 (0.7594), Accuracy: 75.1%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 12 [3200/10000 (2%)]\tLoss: 0.7656 (1.0317), Accuracy: 64.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 12 [3200/10000 (2%)]\tLoss: 1.0437 (1.3937), Accuracy: 49.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 12 [3200/10000 (2%)]\tLoss: 1.4430 (1.6675), Accuracy: 37.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 12 [4800/10000 (3%)]\tLoss: 0.5141 (0.6006), Accuracy: 81.1%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 12 [4800/10000 (3%)]\tLoss: 0.6452 (0.7553), Accuracy: 75.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 12 [4800/10000 (3%)]\tLoss: 0.9038 (1.0342), Accuracy: 65.1%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 12 [4800/10000 (3%)]\tLoss: 1.7636 (1.3895), Accuracy: 49.9%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 12 [4800/10000 (3%)]\tLoss: 1.3878 (1.6729), Accuracy: 37.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 12 [6400/10000 (4%)]\tLoss: 0.4239 (0.5971), Accuracy: 81.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 12 [6400/10000 (4%)]\tLoss: 0.6364 (0.7459), Accuracy: 75.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 12 [6400/10000 (4%)]\tLoss: 0.8403 (1.0234), Accuracy: 65.1%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 12 [6400/10000 (4%)]\tLoss: 1.0974 (1.3810), Accuracy: 50.1%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 12 [6400/10000 (4%)]\tLoss: 1.7467 (1.6728), Accuracy: 37.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 12 [8000/10000 (5%)]\tLoss: 0.5092 (0.5872), Accuracy: 81.1%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 12 [8000/10000 (5%)]\tLoss: 0.5506 (0.7365), Accuracy: 75.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 12 [8000/10000 (5%)]\tLoss: 1.1420 (1.0184), Accuracy: 65.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 12 [8000/10000 (5%)]\tLoss: 1.1938 (1.3735), Accuracy: 50.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 12 [8000/10000 (5%)]\tLoss: 1.3628 (1.6709), Accuracy: 37.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 12 [9600/10000 (6%)]\tLoss: 0.9177 (0.5821), Accuracy: 81.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 12 [9600/10000 (6%)]\tLoss: 0.5668 (0.7300), Accuracy: 76.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 12 [9600/10000 (6%)]\tLoss: 1.0829 (1.0136), Accuracy: 65.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 12 [9600/10000 (6%)]\tLoss: 1.0715 (1.3755), Accuracy: 50.7%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 12 [9600/10000 (6%)]\tLoss: 1.8860 (1.6730), Accuracy: 37.1%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 0.4685, Accuracy: 1715/2000 (86%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 0.4608, Accuracy: 1707/2000 (85%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 0.7420, Accuracy: 1522/2000 (76%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.2769, Accuracy: 1099/2000 (55%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.6098, Accuracy: 825/2000 (41%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 13 [0/10000 (0%)]\tLoss: 0.6427 (0.6427), Accuracy: 81.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 13 [0/10000 (0%)]\tLoss: 1.1291 (1.1291), Accuracy: 75.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 13 [0/10000 (0%)]\tLoss: 1.7511 (1.7511), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 13 [0/10000 (0%)]\tLoss: 1.7727 (1.7727), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 13 [0/10000 (0%)]\tLoss: 1.5455 (1.5455), Accuracy: 43.8%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 13 [1600/10000 (1%)]\tLoss: 0.3918 (0.5842), Accuracy: 81.7%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 13 [1600/10000 (1%)]\tLoss: 0.4627 (0.7193), Accuracy: 77.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 13 [1600/10000 (1%)]\tLoss: 0.9215 (0.9578), Accuracy: 67.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 13 [1600/10000 (1%)]\tLoss: 1.4122 (1.3854), Accuracy: 50.7%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 13 [1600/10000 (1%)]\tLoss: 2.2679 (1.6846), Accuracy: 35.6%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 13 [3200/10000 (2%)]\tLoss: 0.4016 (0.5701), Accuracy: 81.9%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 13 [3200/10000 (2%)]\tLoss: 0.2876 (0.7097), Accuracy: 77.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 13 [3200/10000 (2%)]\tLoss: 0.5278 (0.9732), Accuracy: 66.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 13 [3200/10000 (2%)]\tLoss: 0.9280 (1.3673), Accuracy: 50.7%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 13 [3200/10000 (2%)]\tLoss: 1.3974 (1.6794), Accuracy: 36.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 13 [4800/10000 (3%)]\tLoss: 0.5188 (0.5750), Accuracy: 81.7%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 13 [4800/10000 (3%)]\tLoss: 0.3634 (0.7078), Accuracy: 77.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 13 [4800/10000 (3%)]\tLoss: 0.8862 (0.9758), Accuracy: 66.4%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 13 [4800/10000 (3%)]\tLoss: 1.0289 (1.3628), Accuracy: 51.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 13 [4800/10000 (3%)]\tLoss: 1.3872 (1.6694), Accuracy: 36.8%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 13 [6400/10000 (4%)]\tLoss: 0.2383 (0.5702), Accuracy: 82.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 13 [6400/10000 (4%)]\tLoss: 0.3200 (0.7000), Accuracy: 77.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 13 [6400/10000 (4%)]\tLoss: 0.6913 (0.9759), Accuracy: 66.3%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 13 [6400/10000 (4%)]\tLoss: 1.4295 (1.3574), Accuracy: 51.4%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 13 [6400/10000 (4%)]\tLoss: 1.5504 (1.6679), Accuracy: 37.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 13 [8000/10000 (5%)]\tLoss: 0.3146 (0.5661), Accuracy: 82.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 13 [8000/10000 (5%)]\tLoss: 0.3281 (0.7001), Accuracy: 77.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 13 [8000/10000 (5%)]\tLoss: 0.9377 (0.9800), Accuracy: 66.4%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 13 [8000/10000 (5%)]\tLoss: 1.4578 (1.3534), Accuracy: 51.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 13 [8000/10000 (5%)]\tLoss: 1.5011 (1.6683), Accuracy: 37.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 13 [9600/10000 (6%)]\tLoss: 0.2785 (0.5544), Accuracy: 82.6%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 13 [9600/10000 (6%)]\tLoss: 0.6743 (0.6886), Accuracy: 78.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 13 [9600/10000 (6%)]\tLoss: 0.8243 (0.9745), Accuracy: 66.7%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 13 [9600/10000 (6%)]\tLoss: 1.4663 (1.3437), Accuracy: 52.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 13 [9600/10000 (6%)]\tLoss: 1.6313 (1.6610), Accuracy: 37.5%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 0.4773, Accuracy: 1713/2000 (86%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 0.4605, Accuracy: 1703/2000 (85%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 0.6849, Accuracy: 1548/2000 (77%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.2434, Accuracy: 1148/2000 (57%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.5659, Accuracy: 841/2000 (42%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 14 [0/10000 (0%)]\tLoss: 0.5465 (0.5465), Accuracy: 81.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 14 [0/10000 (0%)]\tLoss: 0.5047 (0.5047), Accuracy: 81.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 14 [0/10000 (0%)]\tLoss: 1.0240 (1.0240), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 14 [0/10000 (0%)]\tLoss: 1.1371 (1.1371), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 14 [0/10000 (0%)]\tLoss: 1.3438 (1.3438), Accuracy: 75.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 14 [1600/10000 (1%)]\tLoss: 0.5271 (0.5158), Accuracy: 83.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 14 [1600/10000 (1%)]\tLoss: 0.6594 (0.6566), Accuracy: 78.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 14 [1600/10000 (1%)]\tLoss: 0.7844 (0.9311), Accuracy: 68.1%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 14 [1600/10000 (1%)]\tLoss: 0.9790 (1.2856), Accuracy: 54.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 14 [1600/10000 (1%)]\tLoss: 1.4123 (1.6052), Accuracy: 40.7%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 14 [3200/10000 (2%)]\tLoss: 0.8401 (0.5336), Accuracy: 83.1%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 14 [3200/10000 (2%)]\tLoss: 0.7293 (0.6674), Accuracy: 78.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 14 [3200/10000 (2%)]\tLoss: 0.5982 (0.9343), Accuracy: 68.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 14 [3200/10000 (2%)]\tLoss: 1.4941 (1.3037), Accuracy: 54.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 14 [3200/10000 (2%)]\tLoss: 1.9007 (1.6274), Accuracy: 39.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 14 [4800/10000 (3%)]\tLoss: 0.4055 (0.5336), Accuracy: 83.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 14 [4800/10000 (3%)]\tLoss: 0.4261 (0.6592), Accuracy: 78.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 14 [4800/10000 (3%)]\tLoss: 1.1509 (0.9418), Accuracy: 67.7%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 14 [4800/10000 (3%)]\tLoss: 1.1929 (1.3015), Accuracy: 54.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 14 [4800/10000 (3%)]\tLoss: 1.5918 (1.6420), Accuracy: 38.7%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 14 [6400/10000 (4%)]\tLoss: 0.3490 (0.5474), Accuracy: 82.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 14 [6400/10000 (4%)]\tLoss: 0.5480 (0.6641), Accuracy: 78.4%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 14 [6400/10000 (4%)]\tLoss: 1.1424 (0.9470), Accuracy: 67.9%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 14 [6400/10000 (4%)]\tLoss: 1.3796 (1.3094), Accuracy: 53.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 14 [6400/10000 (4%)]\tLoss: 1.8564 (1.6487), Accuracy: 38.7%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 14 [8000/10000 (5%)]\tLoss: 0.2918 (0.5368), Accuracy: 83.1%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 14 [8000/10000 (5%)]\tLoss: 0.4363 (0.6615), Accuracy: 78.4%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 14 [8000/10000 (5%)]\tLoss: 1.1260 (0.9458), Accuracy: 67.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 14 [8000/10000 (5%)]\tLoss: 1.2693 (1.3063), Accuracy: 53.9%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 14 [8000/10000 (5%)]\tLoss: 1.7246 (1.6529), Accuracy: 38.7%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 14 [9600/10000 (6%)]\tLoss: 0.2260 (0.5426), Accuracy: 83.1%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 14 [9600/10000 (6%)]\tLoss: 0.3999 (0.6632), Accuracy: 78.4%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 14 [9600/10000 (6%)]\tLoss: 0.9187 (0.9434), Accuracy: 67.9%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 14 [9600/10000 (6%)]\tLoss: 1.5659 (1.2986), Accuracy: 54.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 14 [9600/10000 (6%)]\tLoss: 1.2391 (1.6474), Accuracy: 38.8%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 0.4470, Accuracy: 1727/2000 (86%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 0.4458, Accuracy: 1718/2000 (86%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 0.6495, Accuracy: 1579/2000 (79%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.2614, Accuracy: 1123/2000 (56%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.5747, Accuracy: 821/2000 (41%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 15 [0/10000 (0%)]\tLoss: 0.3682 (0.3682), Accuracy: 93.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 15 [0/10000 (0%)]\tLoss: 0.2219 (0.2219), Accuracy: 100.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 15 [0/10000 (0%)]\tLoss: 0.8844 (0.8844), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 15 [0/10000 (0%)]\tLoss: 1.2330 (1.2330), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 15 [0/10000 (0%)]\tLoss: 1.9712 (1.9712), Accuracy: 31.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 15 [1600/10000 (1%)]\tLoss: 0.7832 (0.5150), Accuracy: 84.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 15 [1600/10000 (1%)]\tLoss: 0.7507 (0.6254), Accuracy: 80.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 15 [1600/10000 (1%)]\tLoss: 0.6436 (0.8921), Accuracy: 70.4%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 15 [1600/10000 (1%)]\tLoss: 1.2405 (1.3052), Accuracy: 54.4%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 15 [1600/10000 (1%)]\tLoss: 1.5085 (1.6708), Accuracy: 37.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 15 [3200/10000 (2%)]\tLoss: 0.2625 (0.5084), Accuracy: 84.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 15 [3200/10000 (2%)]\tLoss: 0.7123 (0.6295), Accuracy: 80.4%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 15 [3200/10000 (2%)]\tLoss: 0.7897 (0.8802), Accuracy: 69.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 15 [3200/10000 (2%)]\tLoss: 1.2367 (1.2966), Accuracy: 53.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 15 [3200/10000 (2%)]\tLoss: 1.9218 (1.6504), Accuracy: 37.7%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 15 [4800/10000 (3%)]\tLoss: 0.1734 (0.5155), Accuracy: 84.1%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 15 [4800/10000 (3%)]\tLoss: 0.4340 (0.6297), Accuracy: 80.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 15 [4800/10000 (3%)]\tLoss: 0.8039 (0.8845), Accuracy: 69.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 15 [4800/10000 (3%)]\tLoss: 1.2099 (1.2793), Accuracy: 54.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 15 [4800/10000 (3%)]\tLoss: 1.7130 (1.6402), Accuracy: 38.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 15 [6400/10000 (4%)]\tLoss: 0.5115 (0.5180), Accuracy: 84.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 15 [6400/10000 (4%)]\tLoss: 0.2873 (0.6248), Accuracy: 80.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 15 [6400/10000 (4%)]\tLoss: 1.0935 (0.8767), Accuracy: 70.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 15 [6400/10000 (4%)]\tLoss: 1.3817 (1.2733), Accuracy: 54.9%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 15 [6400/10000 (4%)]\tLoss: 1.2743 (1.6382), Accuracy: 38.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 15 [8000/10000 (5%)]\tLoss: 0.6887 (0.5216), Accuracy: 83.9%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 15 [8000/10000 (5%)]\tLoss: 0.6987 (0.6331), Accuracy: 79.9%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 15 [8000/10000 (5%)]\tLoss: 1.0986 (0.8820), Accuracy: 70.1%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 15 [8000/10000 (5%)]\tLoss: 1.4049 (1.2708), Accuracy: 54.9%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 15 [8000/10000 (5%)]\tLoss: 1.5887 (1.6351), Accuracy: 38.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 15 [9600/10000 (6%)]\tLoss: 0.3650 (0.5226), Accuracy: 83.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 15 [9600/10000 (6%)]\tLoss: 0.4063 (0.6324), Accuracy: 79.9%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 15 [9600/10000 (6%)]\tLoss: 0.7162 (0.8868), Accuracy: 70.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 15 [9600/10000 (6%)]\tLoss: 1.0121 (1.2762), Accuracy: 54.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 15 [9600/10000 (6%)]\tLoss: 1.2389 (1.6344), Accuracy: 38.7%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 0.4678, Accuracy: 1712/2000 (86%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 0.4162, Accuracy: 1753/2000 (88%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 0.6115, Accuracy: 1611/2000 (81%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.1787, Accuracy: 1185/2000 (59%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.5288, Accuracy: 884/2000 (44%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 16 [0/10000 (0%)]\tLoss: 0.3456 (0.3456), Accuracy: 93.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 16 [0/10000 (0%)]\tLoss: 0.8237 (0.8237), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 16 [0/10000 (0%)]\tLoss: 0.5491 (0.5491), Accuracy: 81.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 16 [0/10000 (0%)]\tLoss: 1.2104 (1.2104), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 16 [0/10000 (0%)]\tLoss: 1.6431 (1.6431), Accuracy: 25.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 16 [1600/10000 (1%)]\tLoss: 0.4756 (0.5337), Accuracy: 82.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 16 [1600/10000 (1%)]\tLoss: 1.2547 (0.6286), Accuracy: 78.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 16 [1600/10000 (1%)]\tLoss: 1.1453 (0.8692), Accuracy: 70.4%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 16 [1600/10000 (1%)]\tLoss: 1.4523 (1.2707), Accuracy: 55.1%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 16 [1600/10000 (1%)]\tLoss: 2.0921 (1.6584), Accuracy: 37.6%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 16 [3200/10000 (2%)]\tLoss: 0.5284 (0.5284), Accuracy: 82.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 16 [3200/10000 (2%)]\tLoss: 0.5128 (0.6284), Accuracy: 79.1%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 16 [3200/10000 (2%)]\tLoss: 0.5572 (0.8802), Accuracy: 70.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 16 [3200/10000 (2%)]\tLoss: 1.0698 (1.2642), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 16 [3200/10000 (2%)]\tLoss: 1.2039 (1.6242), Accuracy: 39.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 16 [4800/10000 (3%)]\tLoss: 0.7781 (0.5219), Accuracy: 83.1%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 16 [4800/10000 (3%)]\tLoss: 0.7948 (0.6154), Accuracy: 79.9%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 16 [4800/10000 (3%)]\tLoss: 0.6683 (0.8733), Accuracy: 70.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 16 [4800/10000 (3%)]\tLoss: 1.4373 (1.2546), Accuracy: 55.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 16 [4800/10000 (3%)]\tLoss: 1.6423 (1.6207), Accuracy: 38.9%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 16 [6400/10000 (4%)]\tLoss: 0.2687 (0.5224), Accuracy: 83.4%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 16 [6400/10000 (4%)]\tLoss: 0.3075 (0.6259), Accuracy: 79.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 16 [6400/10000 (4%)]\tLoss: 0.7423 (0.8667), Accuracy: 70.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 16 [6400/10000 (4%)]\tLoss: 1.1839 (1.2512), Accuracy: 56.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 16 [6400/10000 (4%)]\tLoss: 1.7831 (1.6214), Accuracy: 39.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 16 [8000/10000 (5%)]\tLoss: 0.7339 (0.5205), Accuracy: 83.4%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 16 [8000/10000 (5%)]\tLoss: 0.9853 (0.6217), Accuracy: 79.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 16 [8000/10000 (5%)]\tLoss: 1.2719 (0.8679), Accuracy: 70.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 16 [8000/10000 (5%)]\tLoss: 1.4303 (1.2503), Accuracy: 56.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 16 [8000/10000 (5%)]\tLoss: 1.5469 (1.6264), Accuracy: 39.6%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 16 [9600/10000 (6%)]\tLoss: 0.4397 (0.5127), Accuracy: 83.6%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 16 [9600/10000 (6%)]\tLoss: 0.4454 (0.6144), Accuracy: 80.1%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 16 [9600/10000 (6%)]\tLoss: 0.9315 (0.8567), Accuracy: 70.9%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 16 [9600/10000 (6%)]\tLoss: 1.1407 (1.2399), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 16 [9600/10000 (6%)]\tLoss: 1.4797 (1.6191), Accuracy: 39.7%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 0.4527, Accuracy: 1722/2000 (86%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 0.4027, Accuracy: 1749/2000 (87%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 0.5669, Accuracy: 1645/2000 (82%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.1915, Accuracy: 1189/2000 (59%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.5066, Accuracy: 879/2000 (44%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 17 [0/10000 (0%)]\tLoss: 0.1998 (0.1998), Accuracy: 100.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 17 [0/10000 (0%)]\tLoss: 0.5265 (0.5265), Accuracy: 81.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 17 [0/10000 (0%)]\tLoss: 0.5547 (0.5547), Accuracy: 81.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 17 [0/10000 (0%)]\tLoss: 1.2567 (1.2567), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 17 [0/10000 (0%)]\tLoss: 1.6715 (1.6715), Accuracy: 37.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 17 [1600/10000 (1%)]\tLoss: 0.4873 (0.5148), Accuracy: 84.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 17 [1600/10000 (1%)]\tLoss: 0.7084 (0.6287), Accuracy: 80.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 17 [1600/10000 (1%)]\tLoss: 0.9313 (0.8542), Accuracy: 71.7%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 17 [1600/10000 (1%)]\tLoss: 1.5081 (1.2599), Accuracy: 54.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 17 [1600/10000 (1%)]\tLoss: 1.9091 (1.6218), Accuracy: 38.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 17 [3200/10000 (2%)]\tLoss: 0.1888 (0.4841), Accuracy: 84.9%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 17 [3200/10000 (2%)]\tLoss: 0.3398 (0.6116), Accuracy: 80.4%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 17 [3200/10000 (2%)]\tLoss: 0.7005 (0.8431), Accuracy: 72.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 17 [3200/10000 (2%)]\tLoss: 0.7075 (1.2628), Accuracy: 55.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 17 [3200/10000 (2%)]\tLoss: 1.5168 (1.6286), Accuracy: 38.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 17 [4800/10000 (3%)]\tLoss: 0.7609 (0.4755), Accuracy: 84.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 17 [4800/10000 (3%)]\tLoss: 0.9064 (0.5999), Accuracy: 80.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 17 [4800/10000 (3%)]\tLoss: 1.7267 (0.8312), Accuracy: 71.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 17 [4800/10000 (3%)]\tLoss: 1.7029 (1.2481), Accuracy: 55.9%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 17 [4800/10000 (3%)]\tLoss: 2.3262 (1.6129), Accuracy: 38.8%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 17 [6400/10000 (4%)]\tLoss: 0.9197 (0.4804), Accuracy: 84.7%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 17 [6400/10000 (4%)]\tLoss: 0.6829 (0.5972), Accuracy: 80.9%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 17 [6400/10000 (4%)]\tLoss: 0.8270 (0.8227), Accuracy: 72.7%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 17 [6400/10000 (4%)]\tLoss: 1.3363 (1.2338), Accuracy: 56.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 17 [6400/10000 (4%)]\tLoss: 1.5196 (1.6119), Accuracy: 39.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 17 [8000/10000 (5%)]\tLoss: 0.4545 (0.4875), Accuracy: 84.4%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 17 [8000/10000 (5%)]\tLoss: 0.5192 (0.6024), Accuracy: 81.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 17 [8000/10000 (5%)]\tLoss: 0.6247 (0.8361), Accuracy: 72.1%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 17 [8000/10000 (5%)]\tLoss: 1.0829 (1.2374), Accuracy: 56.4%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 17 [8000/10000 (5%)]\tLoss: 1.7145 (1.6172), Accuracy: 39.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 17 [9600/10000 (6%)]\tLoss: 0.1429 (0.4871), Accuracy: 84.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 17 [9600/10000 (6%)]\tLoss: 0.3983 (0.5933), Accuracy: 81.4%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 17 [9600/10000 (6%)]\tLoss: 0.5440 (0.8305), Accuracy: 72.4%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 17 [9600/10000 (6%)]\tLoss: 0.7602 (1.2276), Accuracy: 57.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 17 [9600/10000 (6%)]\tLoss: 1.4355 (1.6151), Accuracy: 39.5%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 0.4294, Accuracy: 1742/2000 (87%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 0.3863, Accuracy: 1765/2000 (88%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 0.5720, Accuracy: 1643/2000 (82%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.1816, Accuracy: 1191/2000 (60%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.5094, Accuracy: 884/2000 (44%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 18 [0/10000 (0%)]\tLoss: 0.5635 (0.5635), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 18 [0/10000 (0%)]\tLoss: 0.8592 (0.8592), Accuracy: 75.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 18 [0/10000 (0%)]\tLoss: 0.9102 (0.9102), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 18 [0/10000 (0%)]\tLoss: 1.2567 (1.2567), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 18 [0/10000 (0%)]\tLoss: 1.4866 (1.4866), Accuracy: 18.8%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 18 [1600/10000 (1%)]\tLoss: 0.6013 (0.4514), Accuracy: 85.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 18 [1600/10000 (1%)]\tLoss: 0.6401 (0.5614), Accuracy: 82.9%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 18 [1600/10000 (1%)]\tLoss: 0.5271 (0.7695), Accuracy: 75.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 18 [1600/10000 (1%)]\tLoss: 1.1912 (1.1606), Accuracy: 61.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 18 [1600/10000 (1%)]\tLoss: 1.6598 (1.5764), Accuracy: 42.9%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 18 [3200/10000 (2%)]\tLoss: 0.3191 (0.4522), Accuracy: 85.4%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 18 [3200/10000 (2%)]\tLoss: 0.3393 (0.5758), Accuracy: 82.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 18 [3200/10000 (2%)]\tLoss: 0.5356 (0.7677), Accuracy: 75.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 18 [3200/10000 (2%)]\tLoss: 0.5995 (1.1560), Accuracy: 59.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 18 [3200/10000 (2%)]\tLoss: 1.2549 (1.5691), Accuracy: 41.7%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 18 [4800/10000 (3%)]\tLoss: 0.5538 (0.4601), Accuracy: 85.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 18 [4800/10000 (3%)]\tLoss: 0.3797 (0.5748), Accuracy: 82.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 18 [4800/10000 (3%)]\tLoss: 0.5537 (0.7762), Accuracy: 74.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 18 [4800/10000 (3%)]\tLoss: 1.2900 (1.1709), Accuracy: 58.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 18 [4800/10000 (3%)]\tLoss: 1.4293 (1.5703), Accuracy: 41.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 18 [6400/10000 (4%)]\tLoss: 0.6742 (0.4733), Accuracy: 84.6%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 18 [6400/10000 (4%)]\tLoss: 1.3573 (0.5883), Accuracy: 81.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 18 [6400/10000 (4%)]\tLoss: 1.2069 (0.7868), Accuracy: 73.7%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 18 [6400/10000 (4%)]\tLoss: 0.9613 (1.1781), Accuracy: 58.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 18 [6400/10000 (4%)]\tLoss: 1.5748 (1.5841), Accuracy: 41.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 18 [8000/10000 (5%)]\tLoss: 0.8428 (0.4840), Accuracy: 84.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 18 [8000/10000 (5%)]\tLoss: 1.0600 (0.5915), Accuracy: 81.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 18 [8000/10000 (5%)]\tLoss: 1.3466 (0.7931), Accuracy: 73.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 18 [8000/10000 (5%)]\tLoss: 1.8699 (1.1847), Accuracy: 58.1%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 18 [8000/10000 (5%)]\tLoss: 2.3723 (1.5882), Accuracy: 40.8%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 18 [9600/10000 (6%)]\tLoss: 0.6468 (0.4870), Accuracy: 84.4%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 18 [9600/10000 (6%)]\tLoss: 0.5611 (0.5965), Accuracy: 81.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 18 [9600/10000 (6%)]\tLoss: 0.7514 (0.8051), Accuracy: 73.3%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 18 [9600/10000 (6%)]\tLoss: 1.2048 (1.1862), Accuracy: 58.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 18 [9600/10000 (6%)]\tLoss: 1.4878 (1.5971), Accuracy: 40.4%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 0.3920, Accuracy: 1755/2000 (88%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 0.3919, Accuracy: 1748/2000 (87%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 0.5450, Accuracy: 1666/2000 (83%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.1266, Accuracy: 1241/2000 (62%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.4677, Accuracy: 895/2000 (45%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 19 [0/10000 (0%)]\tLoss: 0.2456 (0.2456), Accuracy: 87.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 19 [0/10000 (0%)]\tLoss: 0.2878 (0.2878), Accuracy: 87.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 19 [0/10000 (0%)]\tLoss: 0.6127 (0.6127), Accuracy: 75.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 19 [0/10000 (0%)]\tLoss: 0.9192 (0.9192), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 19 [0/10000 (0%)]\tLoss: 1.3509 (1.3509), Accuracy: 43.8%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 19 [1600/10000 (1%)]\tLoss: 0.7117 (0.4679), Accuracy: 85.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 19 [1600/10000 (1%)]\tLoss: 0.6346 (0.5761), Accuracy: 81.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 19 [1600/10000 (1%)]\tLoss: 1.1103 (0.8001), Accuracy: 72.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 19 [1600/10000 (1%)]\tLoss: 0.9767 (1.1625), Accuracy: 59.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 19 [1600/10000 (1%)]\tLoss: 1.5719 (1.5992), Accuracy: 41.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 19 [3200/10000 (2%)]\tLoss: 0.1542 (0.4591), Accuracy: 85.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 19 [3200/10000 (2%)]\tLoss: 0.2319 (0.5733), Accuracy: 81.9%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 19 [3200/10000 (2%)]\tLoss: 0.5089 (0.7863), Accuracy: 73.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 19 [3200/10000 (2%)]\tLoss: 0.7868 (1.1568), Accuracy: 59.1%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 19 [3200/10000 (2%)]\tLoss: 1.3864 (1.5927), Accuracy: 40.7%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 19 [4800/10000 (3%)]\tLoss: 0.1860 (0.4739), Accuracy: 84.9%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 19 [4800/10000 (3%)]\tLoss: 0.5435 (0.5723), Accuracy: 81.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 19 [4800/10000 (3%)]\tLoss: 0.5928 (0.7849), Accuracy: 74.1%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 19 [4800/10000 (3%)]\tLoss: 1.3070 (1.1757), Accuracy: 58.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 19 [4800/10000 (3%)]\tLoss: 1.4290 (1.6101), Accuracy: 40.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 19 [6400/10000 (4%)]\tLoss: 0.3545 (0.4715), Accuracy: 84.9%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 19 [6400/10000 (4%)]\tLoss: 0.4084 (0.5733), Accuracy: 81.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 19 [6400/10000 (4%)]\tLoss: 0.7903 (0.7802), Accuracy: 73.9%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 19 [6400/10000 (4%)]\tLoss: 1.2648 (1.1728), Accuracy: 58.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 19 [6400/10000 (4%)]\tLoss: 1.6574 (1.5949), Accuracy: 41.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 19 [8000/10000 (5%)]\tLoss: 0.7487 (0.4805), Accuracy: 84.6%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 19 [8000/10000 (5%)]\tLoss: 0.7133 (0.5747), Accuracy: 81.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 19 [8000/10000 (5%)]\tLoss: 0.7547 (0.7811), Accuracy: 73.9%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 19 [8000/10000 (5%)]\tLoss: 1.4275 (1.1696), Accuracy: 58.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 19 [8000/10000 (5%)]\tLoss: 1.6187 (1.5893), Accuracy: 41.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 19 [9600/10000 (6%)]\tLoss: 0.9471 (0.4749), Accuracy: 84.7%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 19 [9600/10000 (6%)]\tLoss: 1.0007 (0.5734), Accuracy: 81.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 19 [9600/10000 (6%)]\tLoss: 1.1036 (0.7808), Accuracy: 74.1%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 19 [9600/10000 (6%)]\tLoss: 1.8818 (1.1744), Accuracy: 58.4%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 19 [9600/10000 (6%)]\tLoss: 1.8087 (1.5952), Accuracy: 40.8%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 0.4311, Accuracy: 1737/2000 (87%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 0.3912, Accuracy: 1761/2000 (88%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 0.5126, Accuracy: 1688/2000 (84%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.1836, Accuracy: 1206/2000 (60%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.4860, Accuracy: 892/2000 (45%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 20 [0/10000 (0%)]\tLoss: 0.9801 (0.9801), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 20 [0/10000 (0%)]\tLoss: 1.0762 (1.0762), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 20 [0/10000 (0%)]\tLoss: 0.8617 (0.8617), Accuracy: 68.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 20 [0/10000 (0%)]\tLoss: 1.8110 (1.8110), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 20 [0/10000 (0%)]\tLoss: 2.1606 (2.1606), Accuracy: 25.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 20 [1600/10000 (1%)]\tLoss: 0.4566 (0.4536), Accuracy: 85.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 20 [1600/10000 (1%)]\tLoss: 0.4694 (0.5466), Accuracy: 82.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 20 [1600/10000 (1%)]\tLoss: 0.7980 (0.7645), Accuracy: 74.9%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 20 [1600/10000 (1%)]\tLoss: 1.0366 (1.1579), Accuracy: 59.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 20 [1600/10000 (1%)]\tLoss: 1.4358 (1.5741), Accuracy: 41.9%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 20 [3200/10000 (2%)]\tLoss: 0.2080 (0.4657), Accuracy: 85.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 20 [3200/10000 (2%)]\tLoss: 0.3387 (0.5447), Accuracy: 83.1%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 20 [3200/10000 (2%)]\tLoss: 0.5834 (0.7829), Accuracy: 74.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 20 [3200/10000 (2%)]\tLoss: 0.8288 (1.1673), Accuracy: 59.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 20 [3200/10000 (2%)]\tLoss: 1.2429 (1.5965), Accuracy: 41.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 20 [4800/10000 (3%)]\tLoss: 0.1322 (0.4623), Accuracy: 85.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 20 [4800/10000 (3%)]\tLoss: 0.3106 (0.5484), Accuracy: 82.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 20 [4800/10000 (3%)]\tLoss: 0.4378 (0.7788), Accuracy: 74.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 20 [4800/10000 (3%)]\tLoss: 0.8748 (1.1618), Accuracy: 59.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 20 [4800/10000 (3%)]\tLoss: 1.3626 (1.5991), Accuracy: 40.8%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 20 [6400/10000 (4%)]\tLoss: 0.2644 (0.4680), Accuracy: 85.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 20 [6400/10000 (4%)]\tLoss: 0.3053 (0.5512), Accuracy: 82.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 20 [6400/10000 (4%)]\tLoss: 0.4412 (0.7722), Accuracy: 74.7%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 20 [6400/10000 (4%)]\tLoss: 0.7523 (1.1635), Accuracy: 59.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 20 [6400/10000 (4%)]\tLoss: 1.9493 (1.5946), Accuracy: 41.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 20 [8000/10000 (5%)]\tLoss: 0.1361 (0.4640), Accuracy: 85.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 20 [8000/10000 (5%)]\tLoss: 0.3575 (0.5509), Accuracy: 82.6%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 20 [8000/10000 (5%)]\tLoss: 0.4318 (0.7664), Accuracy: 75.1%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 20 [8000/10000 (5%)]\tLoss: 1.0051 (1.1635), Accuracy: 59.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 20 [8000/10000 (5%)]\tLoss: 1.6351 (1.5924), Accuracy: 41.4%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 20 [9600/10000 (6%)]\tLoss: 0.6706 (0.4647), Accuracy: 85.4%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 20 [9600/10000 (6%)]\tLoss: 0.5204 (0.5477), Accuracy: 82.4%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 20 [9600/10000 (6%)]\tLoss: 1.1010 (0.7602), Accuracy: 75.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 20 [9600/10000 (6%)]\tLoss: 1.4315 (1.1607), Accuracy: 59.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 20 [9600/10000 (6%)]\tLoss: 1.6457 (1.5930), Accuracy: 40.9%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 0.3841, Accuracy: 1764/2000 (88%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 0.3709, Accuracy: 1762/2000 (88%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 0.4950, Accuracy: 1710/2000 (86%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.0676, Accuracy: 1278/2000 (64%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.4600, Accuracy: 905/2000 (45%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.arange(n_epochs)\n",
        "for val_loss, model_type in zip(val_losses, models):\n",
        "    plt.plot(x, val_loss, label=str(model_type), c=np.random.rand(3,))\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BNuMDVOtAo9v",
        "outputId": "b35f1af9-a0a8-4f24-8e08-2f88c96e7d73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "learning_rate = 2e-4\n",
        "n_epochs = 100"
      ],
      "metadata": {
        "id": "epF7Xu44AvyM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "          GroupEquivariantNet('C C C C C C C', kernel_size=5, padding=1),\n",
        "          GroupEquivariantNet('C C C C C C P', kernel_size=5, padding=1),\n",
        "          GroupEquivariantNet('C C C C C P P', kernel_size=5, padding=1),\n",
        "          GroupEquivariantNet('C C C C P P P', kernel_size=5, padding=1),\n",
        "          GroupEquivariantNet('C C C P P P P', kernel_size=5, padding=1),\n",
        "          ]\n",
        "val_losses_kernel_5 = main(models, batch_size, learning_rate, n_epochs, kernel_size=None)"
      ],
      "metadata": {
        "id": "ATmFg4yaA0rj",
        "outputId": "61e8de04-4dc8-4513-8f15-58abd251c129",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [0/10000 (0%)]\tLoss: 2.4325 (2.4325), Accuracy: 12.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [0/10000 (0%)]\tLoss: 2.4344 (2.4344), Accuracy: 6.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [0/10000 (0%)]\tLoss: 2.2513 (2.2513), Accuracy: 6.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [0/10000 (0%)]\tLoss: 2.3670 (2.3670), Accuracy: 6.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [0/10000 (0%)]\tLoss: 2.2989 (2.2989), Accuracy: 12.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [1600/10000 (1%)]\tLoss: 2.2432 (2.3059), Accuracy: 15.1%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [1600/10000 (1%)]\tLoss: 2.1253 (2.3202), Accuracy: 14.4%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [1600/10000 (1%)]\tLoss: 2.2934 (2.3704), Accuracy: 12.1%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [1600/10000 (1%)]\tLoss: 2.2615 (2.3236), Accuracy: 12.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [1600/10000 (1%)]\tLoss: 2.0934 (2.3204), Accuracy: 13.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [3200/10000 (2%)]\tLoss: 1.9536 (2.2129), Accuracy: 20.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [3200/10000 (2%)]\tLoss: 1.8578 (2.2210), Accuracy: 20.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [3200/10000 (2%)]\tLoss: 2.1452 (2.3077), Accuracy: 14.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [3200/10000 (2%)]\tLoss: 1.9843 (2.2639), Accuracy: 16.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [3200/10000 (2%)]\tLoss: 2.0945 (2.2506), Accuracy: 17.4%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [4800/10000 (3%)]\tLoss: 1.9473 (2.1372), Accuracy: 23.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [4800/10000 (3%)]\tLoss: 1.9092 (2.1429), Accuracy: 23.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [4800/10000 (3%)]\tLoss: 1.9961 (2.2433), Accuracy: 17.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [4800/10000 (3%)]\tLoss: 1.9985 (2.1943), Accuracy: 20.4%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [4800/10000 (3%)]\tLoss: 2.1006 (2.1995), Accuracy: 20.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [6400/10000 (4%)]\tLoss: 1.7811 (2.0587), Accuracy: 26.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [6400/10000 (4%)]\tLoss: 1.8050 (2.0777), Accuracy: 25.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [6400/10000 (4%)]\tLoss: 2.0060 (2.1853), Accuracy: 20.4%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [6400/10000 (4%)]\tLoss: 1.8955 (2.1308), Accuracy: 23.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [6400/10000 (4%)]\tLoss: 2.0056 (2.1439), Accuracy: 22.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [8000/10000 (5%)]\tLoss: 2.1022 (1.9900), Accuracy: 29.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [8000/10000 (5%)]\tLoss: 1.8561 (2.0242), Accuracy: 27.6%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [8000/10000 (5%)]\tLoss: 2.1248 (2.1348), Accuracy: 22.7%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [8000/10000 (5%)]\tLoss: 1.9908 (2.0759), Accuracy: 25.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [8000/10000 (5%)]\tLoss: 1.9966 (2.0964), Accuracy: 23.9%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [9600/10000 (6%)]\tLoss: 1.5168 (1.9301), Accuracy: 31.9%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [9600/10000 (6%)]\tLoss: 1.6005 (1.9735), Accuracy: 29.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [9600/10000 (6%)]\tLoss: 1.6250 (2.0926), Accuracy: 24.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [9600/10000 (6%)]\tLoss: 1.5440 (2.0352), Accuracy: 26.7%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [9600/10000 (6%)]\tLoss: 1.6770 (2.0613), Accuracy: 25.2%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 2.1693, Accuracy: 470/2000 (24%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 1.9431, Accuracy: 625/2000 (31%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 3.1877, Accuracy: 291/2000 (15%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 2.0271, Accuracy: 561/2000 (28%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 2.1848, Accuracy: 401/2000 (20%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [0/10000 (0%)]\tLoss: 1.6831 (1.6831), Accuracy: 37.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [0/10000 (0%)]\tLoss: 1.7634 (1.7634), Accuracy: 37.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [0/10000 (0%)]\tLoss: 1.9205 (1.9205), Accuracy: 18.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [0/10000 (0%)]\tLoss: 1.7891 (1.7891), Accuracy: 31.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [0/10000 (0%)]\tLoss: 1.9084 (1.9084), Accuracy: 25.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [1600/10000 (1%)]\tLoss: 2.1235 (1.5065), Accuracy: 49.4%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [1600/10000 (1%)]\tLoss: 2.3345 (1.6403), Accuracy: 44.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [1600/10000 (1%)]\tLoss: 2.5818 (1.8040), Accuracy: 37.1%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [1600/10000 (1%)]\tLoss: 2.5589 (1.7464), Accuracy: 38.7%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [1600/10000 (1%)]\tLoss: 2.3905 (1.8027), Accuracy: 35.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [3200/10000 (2%)]\tLoss: 1.8320 (1.5067), Accuracy: 49.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [3200/10000 (2%)]\tLoss: 1.8704 (1.6069), Accuracy: 46.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [3200/10000 (2%)]\tLoss: 1.9831 (1.7942), Accuracy: 37.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [3200/10000 (2%)]\tLoss: 1.8574 (1.7568), Accuracy: 36.9%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [3200/10000 (2%)]\tLoss: 2.0839 (1.8021), Accuracy: 35.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [4800/10000 (3%)]\tLoss: 1.4433 (1.4813), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [4800/10000 (3%)]\tLoss: 1.6791 (1.5741), Accuracy: 47.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [4800/10000 (3%)]\tLoss: 1.9911 (1.7583), Accuracy: 39.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [4800/10000 (3%)]\tLoss: 1.7247 (1.7285), Accuracy: 38.1%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [4800/10000 (3%)]\tLoss: 1.7665 (1.7863), Accuracy: 35.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [6400/10000 (4%)]\tLoss: 1.3028 (1.4502), Accuracy: 51.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [6400/10000 (4%)]\tLoss: 1.4632 (1.5362), Accuracy: 48.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [6400/10000 (4%)]\tLoss: 1.4128 (1.7183), Accuracy: 41.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [6400/10000 (4%)]\tLoss: 1.5094 (1.7119), Accuracy: 38.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [6400/10000 (4%)]\tLoss: 1.6699 (1.7702), Accuracy: 35.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [8000/10000 (5%)]\tLoss: 1.1751 (1.4168), Accuracy: 52.6%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [8000/10000 (5%)]\tLoss: 1.4816 (1.5023), Accuracy: 49.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [8000/10000 (5%)]\tLoss: 1.4249 (1.6748), Accuracy: 43.3%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [8000/10000 (5%)]\tLoss: 1.6600 (1.6861), Accuracy: 39.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [8000/10000 (5%)]\tLoss: 1.6964 (1.7499), Accuracy: 36.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [9600/10000 (6%)]\tLoss: 1.0956 (1.3871), Accuracy: 53.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [9600/10000 (6%)]\tLoss: 1.0551 (1.4716), Accuracy: 51.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [9600/10000 (6%)]\tLoss: 1.3069 (1.6382), Accuracy: 44.7%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [9600/10000 (6%)]\tLoss: 1.4307 (1.6666), Accuracy: 40.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [9600/10000 (6%)]\tLoss: 1.4615 (1.7363), Accuracy: 37.0%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 1.1904, Accuracy: 1282/2000 (64%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 1.1063, Accuracy: 1324/2000 (66%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 1.5144, Accuracy: 954/2000 (48%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.5823, Accuracy: 928/2000 (46%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.6757, Accuracy: 741/2000 (37%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [0/10000 (0%)]\tLoss: 1.1955 (1.1955), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [0/10000 (0%)]\tLoss: 1.1696 (1.1696), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [0/10000 (0%)]\tLoss: 1.3257 (1.3257), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [0/10000 (0%)]\tLoss: 1.2693 (1.2693), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [0/10000 (0%)]\tLoss: 1.5318 (1.5318), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [1600/10000 (1%)]\tLoss: 0.9803 (1.1398), Accuracy: 62.1%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [1600/10000 (1%)]\tLoss: 1.1559 (1.2074), Accuracy: 60.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [1600/10000 (1%)]\tLoss: 1.1807 (1.3417), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [1600/10000 (1%)]\tLoss: 1.4770 (1.4577), Accuracy: 48.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [1600/10000 (1%)]\tLoss: 1.4936 (1.6040), Accuracy: 40.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [3200/10000 (2%)]\tLoss: 0.9043 (1.1233), Accuracy: 63.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [3200/10000 (2%)]\tLoss: 1.1735 (1.1863), Accuracy: 60.9%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [3200/10000 (2%)]\tLoss: 1.2988 (1.3207), Accuracy: 57.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [3200/10000 (2%)]\tLoss: 1.4899 (1.4616), Accuracy: 48.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [3200/10000 (2%)]\tLoss: 1.4062 (1.5883), Accuracy: 41.4%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [4800/10000 (3%)]\tLoss: 1.1585 (1.0883), Accuracy: 64.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [4800/10000 (3%)]\tLoss: 1.0389 (1.1596), Accuracy: 62.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [4800/10000 (3%)]\tLoss: 1.3377 (1.2881), Accuracy: 58.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [4800/10000 (3%)]\tLoss: 1.2989 (1.4303), Accuracy: 49.7%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [4800/10000 (3%)]\tLoss: 1.7001 (1.5738), Accuracy: 42.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [6400/10000 (4%)]\tLoss: 1.0919 (1.0566), Accuracy: 66.6%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [6400/10000 (4%)]\tLoss: 1.4247 (1.1340), Accuracy: 63.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [6400/10000 (4%)]\tLoss: 1.4586 (1.2560), Accuracy: 59.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [6400/10000 (4%)]\tLoss: 1.5531 (1.4082), Accuracy: 50.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [6400/10000 (4%)]\tLoss: 1.6376 (1.5517), Accuracy: 43.6%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [8000/10000 (5%)]\tLoss: 0.9393 (1.0271), Accuracy: 67.7%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [8000/10000 (5%)]\tLoss: 0.9977 (1.1071), Accuracy: 64.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [8000/10000 (5%)]\tLoss: 1.1334 (1.2284), Accuracy: 60.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [8000/10000 (5%)]\tLoss: 1.3736 (1.3868), Accuracy: 51.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [8000/10000 (5%)]\tLoss: 1.4241 (1.5252), Accuracy: 45.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [9600/10000 (6%)]\tLoss: 1.0855 (1.0013), Accuracy: 68.7%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [9600/10000 (6%)]\tLoss: 0.8908 (1.0846), Accuracy: 65.1%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [9600/10000 (6%)]\tLoss: 1.0818 (1.2002), Accuracy: 61.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [9600/10000 (6%)]\tLoss: 1.2534 (1.3635), Accuracy: 52.3%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [9600/10000 (6%)]\tLoss: 1.3898 (1.5059), Accuracy: 45.7%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 0.7113, Accuracy: 1593/2000 (80%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 0.7882, Accuracy: 1509/2000 (75%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 1.0788, Accuracy: 1253/2000 (63%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 1.1376, Accuracy: 1263/2000 (63%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 1.2956, Accuracy: 1166/2000 (58%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [0/10000 (0%)]\tLoss: 0.6243 (0.6243), Accuracy: 93.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [0/10000 (0%)]\tLoss: 0.7875 (0.7875), Accuracy: 68.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [0/10000 (0%)]\tLoss: 0.8639 (0.8639), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [0/10000 (0%)]\tLoss: 0.9846 (0.9846), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [0/10000 (0%)]\tLoss: 1.3493 (1.3493), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [1600/10000 (1%)]\tLoss: 1.0154 (0.8010), Accuracy: 76.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [1600/10000 (1%)]\tLoss: 0.8050 (0.8724), Accuracy: 73.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [1600/10000 (1%)]\tLoss: 1.4140 (0.9824), Accuracy: 69.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [1600/10000 (1%)]\tLoss: 1.3285 (1.1384), Accuracy: 62.9%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [1600/10000 (1%)]\tLoss: 1.3742 (1.3271), Accuracy: 52.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [3200/10000 (2%)]\tLoss: 0.7622 (0.7992), Accuracy: 75.9%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [3200/10000 (2%)]\tLoss: 0.9848 (0.8717), Accuracy: 73.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [3200/10000 (2%)]\tLoss: 1.0114 (0.9842), Accuracy: 69.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [3200/10000 (2%)]\tLoss: 1.4861 (1.1439), Accuracy: 62.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [3200/10000 (2%)]\tLoss: 1.3828 (1.3223), Accuracy: 53.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [4800/10000 (3%)]\tLoss: 0.9714 (0.7835), Accuracy: 76.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [4800/10000 (3%)]\tLoss: 0.8680 (0.8653), Accuracy: 73.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [4800/10000 (3%)]\tLoss: 0.9952 (0.9653), Accuracy: 69.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [4800/10000 (3%)]\tLoss: 1.0227 (1.1214), Accuracy: 63.4%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [4800/10000 (3%)]\tLoss: 1.1585 (1.2979), Accuracy: 54.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [6400/10000 (4%)]\tLoss: 0.6608 (0.7621), Accuracy: 76.7%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [6400/10000 (4%)]\tLoss: 0.8516 (0.8540), Accuracy: 73.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [6400/10000 (4%)]\tLoss: 0.9151 (0.9469), Accuracy: 70.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [6400/10000 (4%)]\tLoss: 1.2818 (1.1067), Accuracy: 63.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [6400/10000 (4%)]\tLoss: 1.3226 (1.2783), Accuracy: 55.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.arange(n_epochs)\n",
        "for val_loss, model_type in zip(val_losses_kernel_5, models):\n",
        "    plt.plot(x, val_loss, label=str(model_type), c=np.random.rand(3,))\n",
        "plt.ylim([0, .5])\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DZrg-V0rA4gO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = 7\n",
        "padding = 2\n",
        "models = [\n",
        "          GroupEquivariantNet('C C C C C C C', kernel_size=kernel_size, padding=padding),\n",
        "          GroupEquivariantNet('C C C C C C P', kernel_size=kernel_size, padding=padding),\n",
        "          GroupEquivariantNet('C C C C C P P', kernel_size=kernel_size, padding=padding),\n",
        "          GroupEquivariantNet('C C C C P P P', kernel_size=kernel_size, padding=padding),\n",
        "          GroupEquivariantNet('C C C P P P P', kernel_size=kernel_size, padding=padding),\n",
        "          ]\n",
        "val_losses_kernel_5 = main(models, batch_size, learning_rate, n_epochs, kernel_size=None)"
      ],
      "metadata": {
        "id": "7yWx-8eNA7cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = 9\n",
        "padding = 2\n",
        "models = [\n",
        "          GroupEquivariantNet('C C C C C C C', kernel_size=kernel_size, padding=padding),\n",
        "          GroupEquivariantNet('C C C C C C P', kernel_size=kernel_size, padding=padding),\n",
        "          GroupEquivariantNet('C C C C C P P', kernel_size=kernel_size, padding=padding),\n",
        "          GroupEquivariantNet('C C C C P P P', kernel_size=kernel_size, padding=padding),\n",
        "          GroupEquivariantNet('C C C P P P P', kernel_size=kernel_size, padding=padding),\n",
        "          ]\n",
        "val_losses_kernel_5 = main(models, batch_size, learning_rate, n_epochs, kernel_size=None)"
      ],
      "metadata": {
        "id": "9qn_aOyBx8R9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.arange(n_epochs)\n",
        "for val_loss, model_type in zip(val_losses_kernel_5, models):\n",
        "    plt.plot(x, val_loss, label=str(model_type), c=np.random.rand(3,))\n",
        "plt.ylim([0, .5])\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jlX950SnA8oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classic_val_losses = main('classic', batch_size, learning_rate, n_epochs)"
      ],
      "metadata": {
        "id": "0wWw5f8lBAEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proposed3_val_losses = main('proposed', batch_size, learning_rate, n_epochs)"
      ],
      "metadata": {
        "id": "DsgfKIReBEPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proposed5_val_losses = main('proposed', batch_size, learning_rate, n_epochs, 5)"
      ],
      "metadata": {
        "id": "829DSn7zBIDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mixed3_val_losses = main('mixed', batch_size, learning_rate, n_epochs, 5)"
      ],
      "metadata": {
        "id": "RQHtjQDEBKZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.arange(n_epochs)\n",
        "plt.plot(x, classic_val_losses, label='classic 3')\n",
        "plt.plot(x, proposed3_val_losses, label='proposed 3', color='green')\n",
        "plt.plot(x, proposed5_val_losses, label='proposed 5', color='red')\n",
        "plt.plot(x, mixed3_val_losses, label='mixed 3', color='orange')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DN8D2V4wBLGE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
