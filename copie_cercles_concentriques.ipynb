{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "copie_cercles_concentriques.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvvrapehi-Wo",
        "outputId": "4669fd48-9ac5-4822-a4ab-e7c51e603b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-28 20:23:59--  http://www.iro.umontreal.ca/~lisa/icml2007data/mnist_rotation_new.zip\n",
            "Resolving www.iro.umontreal.ca (www.iro.umontreal.ca)... 132.204.26.36\n",
            "Connecting to www.iro.umontreal.ca (www.iro.umontreal.ca)|132.204.26.36|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58424278 (56M) [application/zip]\n",
            "Saving to: ‘mnist_rotation_new.zip’\n",
            "\n",
            "mnist_rotation_new. 100%[===================>]  55.72M  63.6MB/s    in 0.9s    \n",
            "\n",
            "2022-02-28 20:24:00 (63.6 MB/s) - ‘mnist_rotation_new.zip’ saved [58424278/58424278]\n",
            "\n",
            "Archive:  mnist_rotation_new.zip\n",
            "  inflating: mnist_all_rotation_normalized_float_train_valid.amat  \n",
            "  inflating: mnist_all_rotation_normalized_float_test.amat  \n"
          ]
        }
      ],
      "source": [
        "!wget http://www.iro.umontreal.ca/~lisa/icml2007data/mnist_rotation_new.zip\n",
        "!unzip mnist_rotation_new.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tagpr-cpjGem"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.loadtxt('mnist_all_rotation_normalized_float_train_valid.amat')"
      ],
      "metadata": {
        "id": "Vssw5PB7jUeu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data[:10000]\n",
        "val_data = data[10000:]\n",
        "assert len(train_data) + len(val_data) == len(data)\n",
        "train_features, train_labels = train_data[..., :-1], train_data[..., -1]\n",
        "val_features, val_labels = val_data[..., :-1], val_data[..., -1]"
      ],
      "metadata": {
        "id": "bBkyohfSjUoT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features = np.reshape(train_features, (-1, 28, 28))\n",
        "val_features = np.reshape(val_features, (-1, 28, 28))"
      ],
      "metadata": {
        "id": "B9-BeuThjdtO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_features[0])\n",
        "plt.title('label: {}'.format(train_labels[0]))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "uY4SHLj3jhio",
        "outputId": "90d9c2d0-5bfc-4aa1-ebb5-976430e0464c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "\n",
        "class RotMNISTDataset(Dataset):\n",
        "    def __init__(self, features, labels, transform):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        features = self.transform(self.features[item])\n",
        "\n",
        "        return features.float(), int(self.labels[item])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "rWHFJ0uRnRVr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.utils import _single, _pair, _triple\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, conv_types, kernel_size=3, padding=0):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv_layers = []\n",
        "        # n_inputs_width_fc = 28\n",
        "        for c, conv_type in enumerate(conv_types.split(' ')):\n",
        "            if conv_type == 'C':\n",
        "                conv_op = nn.Conv2d\n",
        "            elif conv_type == 'P':\n",
        "                conv_op = PolarConvNd\n",
        "            else:\n",
        "                raise ValueError(f'Unknown conv type {conv_type}')\n",
        "            conv_args = [1 if c == 0 else 32 * 2**c, 32 * 2**(c+1), kernel_size, 1, padding]\n",
        "            self.conv_layers.append(conv_op(*conv_args))\n",
        "        self.conv_layers = nn.ModuleList(self.conv_layers)\n",
        "        self.conv_types = conv_types\n",
        "\n",
        "        self.adaptive_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.classification_layer = nn.Linear(32 * 2**(c+1), 10, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for conv_layer in self.conv_layers:\n",
        "            x = conv_layer(x)\n",
        "            x = F.relu(x)\n",
        "        x = self.adaptive_pooling(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.classification_layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class GroupEquivariantNet(nn.Module):\n",
        "    \"\"\" a CNN architecture (Z2CNN) with 7 layers of 3×3 convolutions (4×4 in the final layer), \n",
        "    20 channels in each layer, relu activation functions, batch normalization, dropout, and max-pooling after layer2 \"\"\"\n",
        "    def __init__(self, conv_types, kernel_size=3, padding=0):\n",
        "        super(GroupEquivariantNet, self).__init__()\n",
        "\n",
        "        self.conv_layers = []\n",
        "        self.bn_layers = []\n",
        "        assert len(conv_types.split(' ')) == 7, 'expects 7 conv layers'\n",
        "        # n_inputs_width_fc = 28\n",
        "        for c, conv_type in enumerate(conv_types.split(' ')):\n",
        "            if conv_type == 'C':\n",
        "                conv_op = nn.Conv2d\n",
        "            elif conv_type == 'P':\n",
        "                conv_op = PolarConvNd\n",
        "            else:\n",
        "                raise ValueError(f'Unknown conv type {conv_type}')\n",
        "            conv_args = [1 if c == 0 else 20, 20, kernel_size, 1, padding]\n",
        "            self.conv_layers.append(conv_op(*conv_args))\n",
        "            self.bn_layers.append(nn.BatchNorm2d(20))\n",
        "            # n_inputs_width_fc -= ((kernel_size // 2) - padding) * 2\n",
        "        self.conv_layers = nn.ModuleList(self.conv_layers)\n",
        "        self.bn_layers = nn.ModuleList(self.bn_layers)\n",
        "        self.conv_types = conv_types\n",
        "\n",
        "        self.max_pooling = nn.MaxPool2d((2, 2))\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "        self.adaptive_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.classification_layer = nn.Linear(80, 10, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for c, (conv_layer, bn_layer) in enumerate(zip(self.conv_layers, self.bn_layers)):\n",
        "            x = conv_layer(x)\n",
        "            x = bn_layer(x)\n",
        "            x = F.relu(x)\n",
        "            x = self.dropout(x)\n",
        "            if c == 1:\n",
        "              x = self.max_pooling(x)\n",
        "        # x = self.adaptive_pooling(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.classification_layer(x)\n",
        "        return x\n",
        "\n",
        "    def __repr__(self):\n",
        "        return 'GroupEquivariantNet(' + str(self.conv_types) + ')'\n",
        "\n",
        "\n",
        "class PolarConvNd(torch.nn.modules.conv._ConvNd):\n",
        "    \"\"\" Polar convolution \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0,\n",
        "                 dilation=1, groups=1, bias=True, padding_mode='zeros', dimensions=2):\n",
        "        self.init_kernel_size = kernel_size\n",
        "        assert kernel_size % 2 == 1, 'expected kernel size to be odd, found %d' % kernel_size\n",
        "        self.init_dimensions = dimensions\n",
        "\n",
        "        base_vectors = torch.from_numpy(self.build_base_vectors()).float()\n",
        "        self.true_base_vectors_shape = base_vectors.shape\n",
        "        base_vectors = base_vectors.view(self.true_base_vectors_shape[0],\n",
        "                                                   int(np.prod(self.true_base_vectors_shape[1:])))\n",
        "\n",
        "        inferred_kernel_size = self.true_base_vectors_shape[0]\n",
        "        _kernel_size = _single(inferred_kernel_size)\n",
        "        _stride = _single(stride)\n",
        "        _padding = _single(padding)\n",
        "        _dilation = _single(dilation)\n",
        "        super(PolarConvNd, self).__init__(\n",
        "            in_channels, out_channels, _kernel_size, _stride, _padding, _dilation,\n",
        "            False, _single(0), groups, bias, padding_mode)\n",
        "        \n",
        "        self.register_buffer('base_vectors', base_vectors)\n",
        "\n",
        "        if dimensions == 2:\n",
        "            self.reconstructed_stride = _pair(stride)\n",
        "            self.reconstructed_padding = _pair(padding)\n",
        "            self.reconstructed_dilation = _pair(dilation)\n",
        "            self.reconstructed_conv_op = F.conv2d\n",
        "        elif dimensions == 3:\n",
        "            self.reconstructed_stride = _triple(stride)\n",
        "            self.reconstructed_padding = _triple(padding)\n",
        "            self.reconstructed_dilation = _triple(dilation)\n",
        "            self.reconstructed_conv_op = F.conv3d\n",
        "        else:\n",
        "            raise ValueError('dimension %d not supported' % dimensions)\n",
        "\n",
        "    def build_base_vectors(self):\n",
        "        kernel_size = self.init_kernel_size\n",
        "        dimensions = self.init_dimensions\n",
        "        base_vectors = []\n",
        "        taille = kernel_size\n",
        "        centre = taille/2 - 0.5\n",
        "        for k in range (0,taille//2):\n",
        "            base= np.zeros([taille]*dimensions)\n",
        "            for i in range(taille):\n",
        "                for j in range(taille):\n",
        "                \n",
        "                    if np.sqrt(((i+0.5)-centre)**2 + ((j+0.5)-centre)**2)< k+0.5 and np.sqrt(((i+0.5)-centre)**2 + ((j+0.5)-centre)**2) > k-0.5:\n",
        "                        base[i,j]=1\n",
        "                        base[j,i]=1\n",
        "            base_vectors.append(base)\n",
        "        \n",
        "        base_vectors = np.asarray(base_vectors)\n",
        "        return base_vectors\n",
        "\n",
        "    # @weak_script_method\n",
        "    def forward(self, input):\n",
        "        weight_size = self.weight.shape\n",
        "        weight = torch.mm(self.weight.view(np.prod(weight_size[:-1]), weight_size[-1]), self.base_vectors) \\\n",
        "            .view(*weight_size[:-1], *self.true_base_vectors_shape[1:])\n",
        "        return self.reconstructed_conv_op(input, weight, self.bias, self.reconstructed_stride,\n",
        "                                          self.reconstructed_padding, self.reconstructed_dilation, self.groups)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return ('PolarConv%dd' % self.init_dimensions) + '(' + self.extra_repr() + ')'"
      ],
      "metadata": {
        "id": "dSEOLtzknfmX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = 5\n",
        "padding = kernel_size // 2\n",
        "Net('C P C P', kernel_size, padding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iB936iyUnhXD",
        "outputId": "6f9e10b2-1d00-4169-c297-00ff403e0562"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv_layers): ModuleList(\n",
              "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (1): PolarConv2d(64, 128, kernel_size=(2,), stride=(1,), padding=(2,))\n",
              "    (2): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (3): PolarConv2d(256, 512, kernel_size=(2,), stride=(1,), padding=(2,))\n",
              "  )\n",
              "  (adaptive_pooling): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (classification_layer): Linear(in_features=512, out_features=10, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "\n",
        "def main(models_types, batch_size, learning_rate, n_epochs, kernel_size=3):\n",
        "    cuda_kwargs = {'num_workers': 1, 'pin_memory': True, 'shuffle': True}\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "    \n",
        "    train_dataset = RotMNISTDataset(train_features, train_labels, transform)\n",
        "    val_dataset = RotMNISTDataset(val_features, val_labels, transform)\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, **cuda_kwargs)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, **cuda_kwargs)\n",
        "    \n",
        "    models = []\n",
        "    optimizers = []\n",
        "    for model_type in models_types:\n",
        "        if isinstance(model_type, str):\n",
        "            model = Net(model_type, kernel_size, padding=kernel_size // 2).to(device)\n",
        "        else:\n",
        "            model = model_type.to(device)\n",
        "        models.append(model)\n",
        "        optimizers.append(optim.Adam(model.parameters(), lr=learning_rate))\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    val_losses = [[] for _ in range(len(models))]\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        train(models, device, train_dataloader, loss, optimizers, epoch, models_types)\n",
        "        models_val_loss = val(models, device, val_dataloader, loss, models_types)\n",
        "        [val_losses[i].append(model_val_loss) for i, model_val_loss in enumerate(models_val_loss)]\n",
        "    return val_losses\n",
        "\n",
        "\n",
        "def train(models, device, train_loader, loss_fct, optimizers, epoch, models_types):\n",
        "    [model.train() for model in models]\n",
        "    epoch_losses = [[] for _ in range(len(models))]\n",
        "    corrects = [0 for _ in range(len(models))]\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        for m, (model, optimizer) in enumerate(zip(models, optimizers)):\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = loss_fct(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_losses[m].append(loss.item())\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            corrects[m] += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "              print('{}  Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.4f} ({:.4f}), Accuracy: {:.1f}%'.format(\n",
        "                  models_types[m], epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                  100. * batch_idx / len(train_loader.dataset), loss.item(), np.mean(epoch_losses[m]),\n",
        "                  100. * corrects[m] / (len(epoch_losses[m]) * batch_size)))\n",
        "\n",
        "\n",
        "def val(models, device, val_loader, loss_fct, models_types):\n",
        "    [model.eval() for model in models]\n",
        "    val_losses = [0 for _ in range(len(models))]\n",
        "    corrects = [0 for _ in range(len(models))]\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            for m, model in enumerate(models):\n",
        "                output = model(data)\n",
        "                val_losses[m] += loss_fct(output, target).item()  # sum up batch loss\n",
        "                pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "                corrects[m] += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    val_losses = [val_loss / len(val_loader) for val_loss in val_losses]\n",
        "    for val_loss, model_type, correct, val_loss in zip(val_losses, models_types, corrects, val_losses):\n",
        "        print('\\nval set: {} Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            model_type, val_loss, correct, len(val_loader.dataset),\n",
        "            100. * correct / len(val_loader.dataset)))\n",
        "    return val_losses"
      ],
      "metadata": {
        "id": "dWxhMQJznmMM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computes number of parameters with same filter width\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model, model_name):\n",
        "    table = PrettyTable([model_name, \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "\n",
        "count_parameters(GroupEquivariantNet('C C C C C C C', kernel_size=3, padding=0), 'C C C C C C C')\n",
        "count_parameters(GroupEquivariantNet('C C C C C C P', kernel_size=3, padding=0), 'C C C C C C P')\n",
        "count_parameters(GroupEquivariantNet('C C C C C P P', kernel_size=3, padding=0), 'C C C C C P P')\n",
        "count_parameters(GroupEquivariantNet('C C C C P P P', kernel_size=3, padding=0), 'C C C C P P P')\n",
        "count_parameters(GroupEquivariantNet('C C C P P P P', kernel_size=3, padding=0), 'C C C P P P P')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yg1O5JRnsQl",
        "outputId": "9858ca0d-2adc-4b71-b9c7-dd2db342ec2d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+------------+\n",
            "|        C C C C C C C        | Parameters |\n",
            "+-----------------------------+------------+\n",
            "|     conv_layers.0.weight    |    180     |\n",
            "|      conv_layers.0.bias     |     20     |\n",
            "|     conv_layers.1.weight    |    3600    |\n",
            "|      conv_layers.1.bias     |     20     |\n",
            "|     conv_layers.2.weight    |    3600    |\n",
            "|      conv_layers.2.bias     |     20     |\n",
            "|     conv_layers.3.weight    |    3600    |\n",
            "|      conv_layers.3.bias     |     20     |\n",
            "|     conv_layers.4.weight    |    3600    |\n",
            "|      conv_layers.4.bias     |     20     |\n",
            "|     conv_layers.5.weight    |    3600    |\n",
            "|      conv_layers.5.bias     |     20     |\n",
            "|     conv_layers.6.weight    |    3600    |\n",
            "|      conv_layers.6.bias     |     20     |\n",
            "|      bn_layers.0.weight     |     20     |\n",
            "|       bn_layers.0.bias      |     20     |\n",
            "|      bn_layers.1.weight     |     20     |\n",
            "|       bn_layers.1.bias      |     20     |\n",
            "|      bn_layers.2.weight     |     20     |\n",
            "|       bn_layers.2.bias      |     20     |\n",
            "|      bn_layers.3.weight     |     20     |\n",
            "|       bn_layers.3.bias      |     20     |\n",
            "|      bn_layers.4.weight     |     20     |\n",
            "|       bn_layers.4.bias      |     20     |\n",
            "|      bn_layers.5.weight     |     20     |\n",
            "|       bn_layers.5.bias      |     20     |\n",
            "|      bn_layers.6.weight     |     20     |\n",
            "|       bn_layers.6.bias      |     20     |\n",
            "| classification_layer.weight |    800     |\n",
            "+-----------------------------+------------+\n",
            "Total Trainable Params: 23000\n",
            "+-----------------------------+------------+\n",
            "|        C C C C C C P        | Parameters |\n",
            "+-----------------------------+------------+\n",
            "|     conv_layers.0.weight    |    180     |\n",
            "|      conv_layers.0.bias     |     20     |\n",
            "|     conv_layers.1.weight    |    3600    |\n",
            "|      conv_layers.1.bias     |     20     |\n",
            "|     conv_layers.2.weight    |    3600    |\n",
            "|      conv_layers.2.bias     |     20     |\n",
            "|     conv_layers.3.weight    |    3600    |\n",
            "|      conv_layers.3.bias     |     20     |\n",
            "|     conv_layers.4.weight    |    3600    |\n",
            "|      conv_layers.4.bias     |     20     |\n",
            "|     conv_layers.5.weight    |    3600    |\n",
            "|      conv_layers.5.bias     |     20     |\n",
            "|     conv_layers.6.weight    |    400     |\n",
            "|      conv_layers.6.bias     |     20     |\n",
            "|      bn_layers.0.weight     |     20     |\n",
            "|       bn_layers.0.bias      |     20     |\n",
            "|      bn_layers.1.weight     |     20     |\n",
            "|       bn_layers.1.bias      |     20     |\n",
            "|      bn_layers.2.weight     |     20     |\n",
            "|       bn_layers.2.bias      |     20     |\n",
            "|      bn_layers.3.weight     |     20     |\n",
            "|       bn_layers.3.bias      |     20     |\n",
            "|      bn_layers.4.weight     |     20     |\n",
            "|       bn_layers.4.bias      |     20     |\n",
            "|      bn_layers.5.weight     |     20     |\n",
            "|       bn_layers.5.bias      |     20     |\n",
            "|      bn_layers.6.weight     |     20     |\n",
            "|       bn_layers.6.bias      |     20     |\n",
            "| classification_layer.weight |    800     |\n",
            "+-----------------------------+------------+\n",
            "Total Trainable Params: 19800\n",
            "+-----------------------------+------------+\n",
            "|        C C C C C P P        | Parameters |\n",
            "+-----------------------------+------------+\n",
            "|     conv_layers.0.weight    |    180     |\n",
            "|      conv_layers.0.bias     |     20     |\n",
            "|     conv_layers.1.weight    |    3600    |\n",
            "|      conv_layers.1.bias     |     20     |\n",
            "|     conv_layers.2.weight    |    3600    |\n",
            "|      conv_layers.2.bias     |     20     |\n",
            "|     conv_layers.3.weight    |    3600    |\n",
            "|      conv_layers.3.bias     |     20     |\n",
            "|     conv_layers.4.weight    |    3600    |\n",
            "|      conv_layers.4.bias     |     20     |\n",
            "|     conv_layers.5.weight    |    400     |\n",
            "|      conv_layers.5.bias     |     20     |\n",
            "|     conv_layers.6.weight    |    400     |\n",
            "|      conv_layers.6.bias     |     20     |\n",
            "|      bn_layers.0.weight     |     20     |\n",
            "|       bn_layers.0.bias      |     20     |\n",
            "|      bn_layers.1.weight     |     20     |\n",
            "|       bn_layers.1.bias      |     20     |\n",
            "|      bn_layers.2.weight     |     20     |\n",
            "|       bn_layers.2.bias      |     20     |\n",
            "|      bn_layers.3.weight     |     20     |\n",
            "|       bn_layers.3.bias      |     20     |\n",
            "|      bn_layers.4.weight     |     20     |\n",
            "|       bn_layers.4.bias      |     20     |\n",
            "|      bn_layers.5.weight     |     20     |\n",
            "|       bn_layers.5.bias      |     20     |\n",
            "|      bn_layers.6.weight     |     20     |\n",
            "|       bn_layers.6.bias      |     20     |\n",
            "| classification_layer.weight |    800     |\n",
            "+-----------------------------+------------+\n",
            "Total Trainable Params: 16600\n",
            "+-----------------------------+------------+\n",
            "|        C C C C P P P        | Parameters |\n",
            "+-----------------------------+------------+\n",
            "|     conv_layers.0.weight    |    180     |\n",
            "|      conv_layers.0.bias     |     20     |\n",
            "|     conv_layers.1.weight    |    3600    |\n",
            "|      conv_layers.1.bias     |     20     |\n",
            "|     conv_layers.2.weight    |    3600    |\n",
            "|      conv_layers.2.bias     |     20     |\n",
            "|     conv_layers.3.weight    |    3600    |\n",
            "|      conv_layers.3.bias     |     20     |\n",
            "|     conv_layers.4.weight    |    400     |\n",
            "|      conv_layers.4.bias     |     20     |\n",
            "|     conv_layers.5.weight    |    400     |\n",
            "|      conv_layers.5.bias     |     20     |\n",
            "|     conv_layers.6.weight    |    400     |\n",
            "|      conv_layers.6.bias     |     20     |\n",
            "|      bn_layers.0.weight     |     20     |\n",
            "|       bn_layers.0.bias      |     20     |\n",
            "|      bn_layers.1.weight     |     20     |\n",
            "|       bn_layers.1.bias      |     20     |\n",
            "|      bn_layers.2.weight     |     20     |\n",
            "|       bn_layers.2.bias      |     20     |\n",
            "|      bn_layers.3.weight     |     20     |\n",
            "|       bn_layers.3.bias      |     20     |\n",
            "|      bn_layers.4.weight     |     20     |\n",
            "|       bn_layers.4.bias      |     20     |\n",
            "|      bn_layers.5.weight     |     20     |\n",
            "|       bn_layers.5.bias      |     20     |\n",
            "|      bn_layers.6.weight     |     20     |\n",
            "|       bn_layers.6.bias      |     20     |\n",
            "| classification_layer.weight |    800     |\n",
            "+-----------------------------+------------+\n",
            "Total Trainable Params: 13400\n",
            "+-----------------------------+------------+\n",
            "|        C C C P P P P        | Parameters |\n",
            "+-----------------------------+------------+\n",
            "|     conv_layers.0.weight    |    180     |\n",
            "|      conv_layers.0.bias     |     20     |\n",
            "|     conv_layers.1.weight    |    3600    |\n",
            "|      conv_layers.1.bias     |     20     |\n",
            "|     conv_layers.2.weight    |    3600    |\n",
            "|      conv_layers.2.bias     |     20     |\n",
            "|     conv_layers.3.weight    |    400     |\n",
            "|      conv_layers.3.bias     |     20     |\n",
            "|     conv_layers.4.weight    |    400     |\n",
            "|      conv_layers.4.bias     |     20     |\n",
            "|     conv_layers.5.weight    |    400     |\n",
            "|      conv_layers.5.bias     |     20     |\n",
            "|     conv_layers.6.weight    |    400     |\n",
            "|      conv_layers.6.bias     |     20     |\n",
            "|      bn_layers.0.weight     |     20     |\n",
            "|       bn_layers.0.bias      |     20     |\n",
            "|      bn_layers.1.weight     |     20     |\n",
            "|       bn_layers.1.bias      |     20     |\n",
            "|      bn_layers.2.weight     |     20     |\n",
            "|       bn_layers.2.bias      |     20     |\n",
            "|      bn_layers.3.weight     |     20     |\n",
            "|       bn_layers.3.bias      |     20     |\n",
            "|      bn_layers.4.weight     |     20     |\n",
            "|       bn_layers.4.bias      |     20     |\n",
            "|      bn_layers.5.weight     |     20     |\n",
            "|       bn_layers.5.bias      |     20     |\n",
            "|      bn_layers.6.weight     |     20     |\n",
            "|       bn_layers.6.bias      |     20     |\n",
            "| classification_layer.weight |    800     |\n",
            "+-----------------------------+------------+\n",
            "Total Trainable Params: 10200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10200"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "learning_rate = 2e-4\n",
        "n_epochs = 20"
      ],
      "metadata": {
        "id": "-XLSdoMQoPUO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "          GroupEquivariantNet('C C C C C C C', kernel_size=3, padding=0),\n",
        "          GroupEquivariantNet('C C C C C C P', kernel_size=3, padding=0),\n",
        "          GroupEquivariantNet('C C C C C P P', kernel_size=3, padding=0),\n",
        "          GroupEquivariantNet('C C C C P P P', kernel_size=3, padding=0),\n",
        "          GroupEquivariantNet('C C C P P P P', kernel_size=3, padding=0),\n",
        "          ]\n",
        "val_losses = main(models, batch_size, learning_rate, n_epochs, kernel_size=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mxHv8lnjoQu-",
        "outputId": "cf96522a-d29e-4fc8-83ce-81b7a3439522"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [0/10000 (0%)]\tLoss: 2.2474 (2.2474), Accuracy: 25.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [0/10000 (0%)]\tLoss: 2.3026 (2.3026), Accuracy: 25.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [0/10000 (0%)]\tLoss: 2.3026 (2.3026), Accuracy: 12.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [0/10000 (0%)]\tLoss: 2.3026 (2.3026), Accuracy: 6.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [0/10000 (0%)]\tLoss: 2.3026 (2.3026), Accuracy: 25.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [1600/10000 (1%)]\tLoss: 2.0854 (2.3312), Accuracy: 12.9%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [1600/10000 (1%)]\tLoss: 2.3027 (2.3026), Accuracy: 9.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [1600/10000 (1%)]\tLoss: 2.3024 (2.3026), Accuracy: 11.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [1600/10000 (1%)]\tLoss: 2.3026 (2.3026), Accuracy: 10.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [1600/10000 (1%)]\tLoss: 2.3020 (2.3025), Accuracy: 11.8%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [3200/10000 (2%)]\tLoss: 2.2840 (2.3150), Accuracy: 13.6%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [3200/10000 (2%)]\tLoss: 2.3030 (2.3025), Accuracy: 10.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [3200/10000 (2%)]\tLoss: 2.3026 (2.3026), Accuracy: 10.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [3200/10000 (2%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [3200/10000 (2%)]\tLoss: 2.3021 (2.3026), Accuracy: 11.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [4800/10000 (3%)]\tLoss: 2.1176 (2.2897), Accuracy: 15.3%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [4800/10000 (3%)]\tLoss: 2.3017 (2.3026), Accuracy: 10.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [4800/10000 (3%)]\tLoss: 2.3027 (2.3026), Accuracy: 10.1%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [4800/10000 (3%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [4800/10000 (3%)]\tLoss: 2.3025 (2.3025), Accuracy: 11.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [6400/10000 (4%)]\tLoss: 2.1117 (2.2575), Accuracy: 17.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [6400/10000 (4%)]\tLoss: 2.3027 (2.3026), Accuracy: 10.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [6400/10000 (4%)]\tLoss: 2.3025 (2.3026), Accuracy: 10.1%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [6400/10000 (4%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [6400/10000 (4%)]\tLoss: 2.3027 (2.3025), Accuracy: 11.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [8000/10000 (5%)]\tLoss: 1.9365 (2.2278), Accuracy: 18.9%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [8000/10000 (5%)]\tLoss: 2.3024 (2.3026), Accuracy: 10.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [8000/10000 (5%)]\tLoss: 2.3019 (2.3026), Accuracy: 10.3%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [8000/10000 (5%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.7%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [8000/10000 (5%)]\tLoss: 2.3000 (2.3025), Accuracy: 11.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 1 [9600/10000 (6%)]\tLoss: 1.8529 (2.1942), Accuracy: 20.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 1 [9600/10000 (6%)]\tLoss: 2.3032 (2.3026), Accuracy: 10.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 1 [9600/10000 (6%)]\tLoss: 2.3031 (2.3026), Accuracy: 10.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 1 [9600/10000 (6%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 1 [9600/10000 (6%)]\tLoss: 2.3023 (2.3025), Accuracy: 11.5%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 2.5706, Accuracy: 231/2000 (12%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 2.3026, Accuracy: 186/2000 (9%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 2.3026, Accuracy: 197/2000 (10%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 2.3026, Accuracy: 209/2000 (10%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 2.3020, Accuracy: 223/2000 (11%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [0/10000 (0%)]\tLoss: 2.0830 (2.0830), Accuracy: 31.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [0/10000 (0%)]\tLoss: 2.3017 (2.3017), Accuracy: 6.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [0/10000 (0%)]\tLoss: 2.3019 (2.3019), Accuracy: 18.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [0/10000 (0%)]\tLoss: 2.3026 (2.3026), Accuracy: 12.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [0/10000 (0%)]\tLoss: 2.3000 (2.3000), Accuracy: 12.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [1600/10000 (1%)]\tLoss: 2.0093 (1.9575), Accuracy: 30.9%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [1600/10000 (1%)]\tLoss: 2.3023 (2.3026), Accuracy: 10.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [1600/10000 (1%)]\tLoss: 2.3023 (2.3026), Accuracy: 10.4%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [1600/10000 (1%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [1600/10000 (1%)]\tLoss: 2.3003 (2.3025), Accuracy: 10.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [3200/10000 (2%)]\tLoss: 1.6224 (1.9047), Accuracy: 33.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [3200/10000 (2%)]\tLoss: 2.3030 (2.3025), Accuracy: 10.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [3200/10000 (2%)]\tLoss: 2.3017 (2.3025), Accuracy: 10.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [3200/10000 (2%)]\tLoss: 2.3026 (2.3026), Accuracy: 10.4%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [3200/10000 (2%)]\tLoss: 2.3020 (2.3024), Accuracy: 10.6%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [4800/10000 (3%)]\tLoss: 1.6434 (1.8687), Accuracy: 34.4%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [4800/10000 (3%)]\tLoss: 2.3016 (2.3024), Accuracy: 10.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [4800/10000 (3%)]\tLoss: 2.3014 (2.3024), Accuracy: 11.4%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [4800/10000 (3%)]\tLoss: 2.3026 (2.3026), Accuracy: 10.1%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [4800/10000 (3%)]\tLoss: 2.3000 (2.3022), Accuracy: 11.4%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [6400/10000 (4%)]\tLoss: 2.2868 (1.8456), Accuracy: 35.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [6400/10000 (4%)]\tLoss: 2.3051 (2.3025), Accuracy: 10.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [6400/10000 (4%)]\tLoss: 2.3033 (2.3025), Accuracy: 11.4%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [6400/10000 (4%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [6400/10000 (4%)]\tLoss: 2.3031 (2.3022), Accuracy: 11.4%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [8000/10000 (5%)]\tLoss: 1.6800 (1.8184), Accuracy: 36.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [8000/10000 (5%)]\tLoss: 2.3031 (2.3024), Accuracy: 10.6%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [8000/10000 (5%)]\tLoss: 2.3015 (2.3024), Accuracy: 11.4%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [8000/10000 (5%)]\tLoss: 2.3026 (2.3026), Accuracy: 10.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [8000/10000 (5%)]\tLoss: 2.2990 (2.3022), Accuracy: 11.4%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 2 [9600/10000 (6%)]\tLoss: 1.4844 (1.7918), Accuracy: 37.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 2 [9600/10000 (6%)]\tLoss: 2.3002 (2.3024), Accuracy: 10.7%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 2 [9600/10000 (6%)]\tLoss: 2.3006 (2.3024), Accuracy: 11.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 2 [9600/10000 (6%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.9%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 2 [9600/10000 (6%)]\tLoss: 2.2999 (2.3021), Accuracy: 11.6%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 2.6362, Accuracy: 413/2000 (21%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 2.3023, Accuracy: 223/2000 (11%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 2.3025, Accuracy: 223/2000 (11%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 2.3026, Accuracy: 209/2000 (10%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 2.3018, Accuracy: 223/2000 (11%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [0/10000 (0%)]\tLoss: 1.6118 (1.6118), Accuracy: 50.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [0/10000 (0%)]\tLoss: 2.2957 (2.2957), Accuracy: 25.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [0/10000 (0%)]\tLoss: 2.3016 (2.3016), Accuracy: 12.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [0/10000 (0%)]\tLoss: 2.3026 (2.3026), Accuracy: 0.0%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [0/10000 (0%)]\tLoss: 2.3010 (2.3010), Accuracy: 12.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [1600/10000 (1%)]\tLoss: 1.8088 (1.6454), Accuracy: 41.1%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [1600/10000 (1%)]\tLoss: 2.3004 (2.3022), Accuracy: 10.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [1600/10000 (1%)]\tLoss: 2.2999 (2.3025), Accuracy: 10.7%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [1600/10000 (1%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [1600/10000 (1%)]\tLoss: 2.2990 (2.3026), Accuracy: 10.8%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [3200/10000 (2%)]\tLoss: 1.5205 (1.6095), Accuracy: 43.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [3200/10000 (2%)]\tLoss: 2.3010 (2.3021), Accuracy: 11.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [3200/10000 (2%)]\tLoss: 2.3029 (2.3021), Accuracy: 11.3%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [3200/10000 (2%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [3200/10000 (2%)]\tLoss: 2.3058 (2.3019), Accuracy: 11.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [4800/10000 (3%)]\tLoss: 1.4260 (1.5761), Accuracy: 44.7%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [4800/10000 (3%)]\tLoss: 2.3023 (2.3019), Accuracy: 11.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [4800/10000 (3%)]\tLoss: 2.3029 (2.3020), Accuracy: 11.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [4800/10000 (3%)]\tLoss: 2.3026 (2.3026), Accuracy: 10.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [4800/10000 (3%)]\tLoss: 2.3022 (2.3016), Accuracy: 11.6%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [6400/10000 (4%)]\tLoss: 1.7826 (1.5735), Accuracy: 45.0%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [6400/10000 (4%)]\tLoss: 2.3071 (2.3019), Accuracy: 11.4%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [6400/10000 (4%)]\tLoss: 2.3001 (2.3020), Accuracy: 11.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [6400/10000 (4%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.9%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [6400/10000 (4%)]\tLoss: 2.2981 (2.3016), Accuracy: 11.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [8000/10000 (5%)]\tLoss: 1.5454 (1.5593), Accuracy: 45.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [8000/10000 (5%)]\tLoss: 2.3018 (2.3020), Accuracy: 11.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [8000/10000 (5%)]\tLoss: 2.3036 (2.3021), Accuracy: 11.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [8000/10000 (5%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [8000/10000 (5%)]\tLoss: 2.3055 (2.3017), Accuracy: 11.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 3 [9600/10000 (6%)]\tLoss: 1.3966 (1.5416), Accuracy: 46.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 3 [9600/10000 (6%)]\tLoss: 2.3037 (2.3019), Accuracy: 11.4%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 3 [9600/10000 (6%)]\tLoss: 2.3063 (2.3019), Accuracy: 11.6%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 3 [9600/10000 (6%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 3 [9600/10000 (6%)]\tLoss: 2.3122 (2.3015), Accuracy: 11.6%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 2.1127, Accuracy: 538/2000 (27%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 2.3019, Accuracy: 223/2000 (11%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 2.3017, Accuracy: 223/2000 (11%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 2.3026, Accuracy: 209/2000 (10%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 2.3020, Accuracy: 223/2000 (11%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [0/10000 (0%)]\tLoss: 1.2268 (1.2268), Accuracy: 56.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [0/10000 (0%)]\tLoss: 2.2987 (2.2987), Accuracy: 12.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [0/10000 (0%)]\tLoss: 2.2977 (2.2977), Accuracy: 12.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [0/10000 (0%)]\tLoss: 2.3026 (2.3026), Accuracy: 12.5%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [0/10000 (0%)]\tLoss: 2.2975 (2.2975), Accuracy: 12.5%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [1600/10000 (1%)]\tLoss: 1.2910 (1.3960), Accuracy: 52.2%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [1600/10000 (1%)]\tLoss: 2.3076 (2.3022), Accuracy: 11.1%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [1600/10000 (1%)]\tLoss: 2.3041 (2.3019), Accuracy: 10.9%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [1600/10000 (1%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.9%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [1600/10000 (1%)]\tLoss: 2.3003 (2.3015), Accuracy: 10.9%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [3200/10000 (2%)]\tLoss: 0.9658 (1.3800), Accuracy: 52.9%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [3200/10000 (2%)]\tLoss: 2.2938 (2.3014), Accuracy: 11.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [3200/10000 (2%)]\tLoss: 2.2937 (2.3013), Accuracy: 11.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [3200/10000 (2%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.6%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [3200/10000 (2%)]\tLoss: 2.2956 (2.3008), Accuracy: 11.8%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [4800/10000 (3%)]\tLoss: 1.2307 (1.3824), Accuracy: 52.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [4800/10000 (3%)]\tLoss: 2.2965 (2.3013), Accuracy: 11.8%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [4800/10000 (3%)]\tLoss: 2.2925 (2.3012), Accuracy: 11.8%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [4800/10000 (3%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.7%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [4800/10000 (3%)]\tLoss: 2.2972 (2.3008), Accuracy: 11.8%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [6400/10000 (4%)]\tLoss: 1.2138 (1.3722), Accuracy: 52.9%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [6400/10000 (4%)]\tLoss: 2.2988 (2.3013), Accuracy: 11.6%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [6400/10000 (4%)]\tLoss: 2.3048 (2.3012), Accuracy: 11.7%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [6400/10000 (4%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.7%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [6400/10000 (4%)]\tLoss: 2.2969 (2.3008), Accuracy: 11.7%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [8000/10000 (5%)]\tLoss: 1.3945 (1.3736), Accuracy: 52.9%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [8000/10000 (5%)]\tLoss: 2.3005 (2.3015), Accuracy: 11.3%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [8000/10000 (5%)]\tLoss: 2.2994 (2.3015), Accuracy: 11.3%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [8000/10000 (5%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [8000/10000 (5%)]\tLoss: 2.2955 (2.3011), Accuracy: 11.3%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 4 [9600/10000 (6%)]\tLoss: 1.1622 (1.3567), Accuracy: 53.7%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 4 [9600/10000 (6%)]\tLoss: 2.3085 (2.3015), Accuracy: 11.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 4 [9600/10000 (6%)]\tLoss: 2.3070 (2.3013), Accuracy: 11.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 4 [9600/10000 (6%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.9%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 4 [9600/10000 (6%)]\tLoss: 2.3094 (2.3011), Accuracy: 11.5%\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C C) Average loss: 1.7743, Accuracy: 704/2000 (35%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C C P) Average loss: 2.3020, Accuracy: 223/2000 (11%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C C P P) Average loss: 2.3019, Accuracy: 223/2000 (11%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C C P P P) Average loss: 2.3026, Accuracy: 209/2000 (10%)\n",
            "\n",
            "\n",
            "val set: GroupEquivariantNet(C C C P P P P) Average loss: 2.3021, Accuracy: 223/2000 (11%)\n",
            "\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 5 [0/10000 (0%)]\tLoss: 1.3873 (1.3873), Accuracy: 43.8%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 5 [0/10000 (0%)]\tLoss: 2.2955 (2.2955), Accuracy: 0.0%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 5 [0/10000 (0%)]\tLoss: 2.2991 (2.2991), Accuracy: 0.0%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 5 [0/10000 (0%)]\tLoss: 2.3026 (2.3026), Accuracy: 31.2%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 5 [0/10000 (0%)]\tLoss: 2.2955 (2.2955), Accuracy: 0.0%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 5 [1600/10000 (1%)]\tLoss: 1.2552 (1.2632), Accuracy: 57.4%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 5 [1600/10000 (1%)]\tLoss: 2.3014 (2.3006), Accuracy: 12.2%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 5 [1600/10000 (1%)]\tLoss: 2.2970 (2.3007), Accuracy: 12.2%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 5 [1600/10000 (1%)]\tLoss: 2.3026 (2.3026), Accuracy: 10.1%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 5 [1600/10000 (1%)]\tLoss: 2.2999 (2.3004), Accuracy: 12.2%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 5 [3200/10000 (2%)]\tLoss: 1.4483 (1.2382), Accuracy: 58.7%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 5 [3200/10000 (2%)]\tLoss: 2.3056 (2.3007), Accuracy: 12.1%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 5 [3200/10000 (2%)]\tLoss: 2.3046 (2.3007), Accuracy: 12.1%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 5 [3200/10000 (2%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.8%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 5 [3200/10000 (2%)]\tLoss: 2.3031 (2.3006), Accuracy: 12.1%\n",
            "GroupEquivariantNet(C C C C C C C)  Train Epoch: 5 [4800/10000 (3%)]\tLoss: 1.2336 (1.2334), Accuracy: 58.5%\n",
            "GroupEquivariantNet(C C C C C C P)  Train Epoch: 5 [4800/10000 (3%)]\tLoss: 2.3267 (2.3014), Accuracy: 11.5%\n",
            "GroupEquivariantNet(C C C C C P P)  Train Epoch: 5 [4800/10000 (3%)]\tLoss: 2.3198 (2.3013), Accuracy: 11.5%\n",
            "GroupEquivariantNet(C C C C P P P)  Train Epoch: 5 [4800/10000 (3%)]\tLoss: 2.3026 (2.3026), Accuracy: 9.7%\n",
            "GroupEquivariantNet(C C C P P P P)  Train Epoch: 5 [4800/10000 (3%)]\tLoss: 2.3191 (2.3014), Accuracy: 11.5%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-3c259e822388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mGroupEquivariantNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C C C P P P P'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           ]\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-cea95b823498>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(models_types, batch_size, learning_rate, n_epochs, kernel_size)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mmodels_val_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_val_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_val_loss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_val_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-cea95b823498>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(models, device, train_loader, loss_fct, optimizers, epoch, models_types)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.arange(n_epochs)\n",
        "for val_loss, model_type in zip(val_losses, models):\n",
        "    plt.plot(x, val_loss, label=str(model_type), c=np.random.rand(3,))\n",
        "plt.ylim([0, .5])\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BNuMDVOtAo9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "learning_rate = 2e-4\n",
        "n_epochs = 100"
      ],
      "metadata": {
        "id": "epF7Xu44AvyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "          GroupEquivariantNet('C C C C C C C', kernel_size=5, padding=1),\n",
        "          GroupEquivariantNet('C C C C C C P', kernel_size=5, padding=1),\n",
        "          GroupEquivariantNet('C C C C C P P', kernel_size=5, padding=1),\n",
        "          GroupEquivariantNet('C C C C P P P', kernel_size=5, padding=1),\n",
        "          GroupEquivariantNet('C C C P P P P', kernel_size=5, padding=1),\n",
        "          ]\n",
        "val_losses_kernel_5 = main(models, batch_size, learning_rate, n_epochs, kernel_size=None)"
      ],
      "metadata": {
        "id": "ATmFg4yaA0rj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.arange(n_epochs)\n",
        "for val_loss, model_type in zip(val_losses_kernel_5, models):\n",
        "    plt.plot(x, val_loss, label=str(model_type), c=np.random.rand(3,))\n",
        "plt.ylim([0, .5])\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DZrg-V0rA4gO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_size = 7\n",
        "padding = 2\n",
        "models = [\n",
        "          GroupEquivariantNet('C C C C C C C', kernel_size=kernel_size, padding=padding),\n",
        "          GroupEquivariantNet('C C C C C C P', kernel_size=kernel_size, padding=padding),\n",
        "          GroupEquivariantNet('C C C C C P P', kernel_size=kernel_size, padding=padding),\n",
        "          GroupEquivariantNet('C C C C P P P', kernel_size=kernel_size, padding=padding),\n",
        "          GroupEquivariantNet('C C C P P P P', kernel_size=kernel_size, padding=padding),\n",
        "          ]\n",
        "val_losses_kernel_5 = main(models, batch_size, learning_rate, n_epochs, kernel_size=None)"
      ],
      "metadata": {
        "id": "7yWx-8eNA7cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.arange(n_epochs)\n",
        "for val_loss, model_type in zip(val_losses_kernel_5, models):\n",
        "    plt.plot(x, val_loss, label=str(model_type), c=np.random.rand(3,))\n",
        "plt.ylim([0, .5])\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jlX950SnA8oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classic_val_losses = main('classic', batch_size, learning_rate, n_epochs)"
      ],
      "metadata": {
        "id": "0wWw5f8lBAEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proposed3_val_losses = main('proposed', batch_size, learning_rate, n_epochs)"
      ],
      "metadata": {
        "id": "DsgfKIReBEPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proposed5_val_losses = main('proposed', batch_size, learning_rate, n_epochs, 5)"
      ],
      "metadata": {
        "id": "829DSn7zBIDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mixed3_val_losses = main('mixed', batch_size, learning_rate, n_epochs, 5)"
      ],
      "metadata": {
        "id": "RQHtjQDEBKZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.arange(n_epochs)\n",
        "plt.plot(x, classic_val_losses, label='classic 3')\n",
        "plt.plot(x, proposed3_val_losses, label='proposed 3', color='green')\n",
        "plt.plot(x, proposed5_val_losses, label='proposed 5', color='red')\n",
        "plt.plot(x, mixed3_val_losses, label='mixed 3', color='orange')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DN8D2V4wBLGE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}